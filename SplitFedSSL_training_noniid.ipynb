{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:14.251727Z",
     "iopub.status.busy": "2024-03-01T10:06:14.251597Z",
     "iopub.status.idle": "2024-03-01T10:06:14.817640Z",
     "shell.execute_reply": "2024-03-01T10:06:14.817312Z",
     "shell.execute_reply.started": "2024-03-01T10:06:14.251711Z"
    },
    "id": "UBt1XYXhaqmG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haken/.conda/envs/splitfedssl/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import wraps\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "from torchvision import transforms, utils, datasets\n",
    "from utils.utils import *\n",
    "from utils.training import *\n",
    "# from utils.training_batch import *\n",
    "from utils.model import *\n",
    "from utils.BYOL_models import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:14.818438Z",
     "iopub.status.busy": "2024-03-01T10:06:14.818302Z",
     "iopub.status.idle": "2024-03-01T10:06:14.820004Z",
     "shell.execute_reply": "2024-03-01T10:06:14.819809Z",
     "shell.execute_reply.started": "2024-03-01T10:06:14.818428Z"
    },
    "id": "80RsLgxtasod",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set manual seed for reproducibility\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:14.820336Z",
     "iopub.status.busy": "2024-03-01T10:06:14.820260Z",
     "iopub.status.idle": "2024-03-01T10:06:14.832842Z",
     "shell.execute_reply": "2024-03-01T10:06:14.832648Z",
     "shell.execute_reply.started": "2024-03-01T10:06:14.820329Z"
    },
    "id": "iIARTSyVa0xH",
    "outputId": "7103c049-17fa-4339-a8a2-d2884cac6bf3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f45f017bbb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:14.833223Z",
     "iopub.status.busy": "2024-03-01T10:06:14.833130Z",
     "iopub.status.idle": "2024-03-01T10:06:14.834836Z",
     "shell.execute_reply": "2024-03-01T10:06:14.834633Z",
     "shell.execute_reply.started": "2024-03-01T10:06:14.833213Z"
    },
    "id": "Vv3ALBpva13d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpu training specific\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:14.835181Z",
     "iopub.status.busy": "2024-03-01T10:06:14.835090Z",
     "iopub.status.idle": "2024-03-01T10:06:14.836897Z",
     "shell.execute_reply": "2024-03-01T10:06:14.836698Z",
     "shell.execute_reply.started": "2024-03-01T10:06:14.835172Z"
    }
   },
   "outputs": [],
   "source": [
    "# ('mnist', 'femnist', 'fmnist', 'cifar10', 'cifar100', 'svhn')\n",
    "data_path = \"./data\"\n",
    "dataset = \"cifar10\"\n",
    "# ('noniid-labeldir', 'iid', 'default') default only for femnist\n",
    "partition = \"noniid-labeldir\"\n",
    "client_num = 5\n",
    "batch_size = 32\n",
    "test_batch = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:14.837236Z",
     "iopub.status.busy": "2024-03-01T10:06:14.837147Z",
     "iopub.status.idle": "2024-03-01T10:06:14.839169Z",
     "shell.execute_reply": "2024-03-01T10:06:14.838976Z",
     "shell.execute_reply.started": "2024-03-01T10:06:14.837226Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters_List (H) = [rounds, number_of_clients, number_of_training_rounds_local, local_batch_size, lr_client, aggregation_frequence]\n",
    "\n",
    "global_epochs = 1000\n",
    "lr = 3e-4\n",
    "dirichlet_beta = 0.4\n",
    "norm = 'bn'\n",
    "# every (avg_freq) epochs doing one aggregation\n",
    "# avg_freq = 2\n",
    "avg_freq = \"linear\"\n",
    "\n",
    "# save_path = f\"./model/SplitFSSLMaxpool_resnet18/resnet18Maxpooling_cifar10_{batch_size}_{partition}_{client_num}\"\n",
    "# save_path = f\"./model/SplitFSSL_BYOL_Avg25times/resnet18Maxpooling_cifar10_{batch_size}_{avg_freq}_{partition}_{client_num}\"\n",
    "save_path = f\"./model/SplitFSSL_BYOL32_DifAvgtimes/resnet18Maxpooling_{dataset}_{batch_size}_{avg_freq}_{partition}_{client_num}\"\n",
    "H = [global_epochs, client_num, batch_size, lr, avg_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:14.840035Z",
     "iopub.status.busy": "2024-03-01T10:06:14.839952Z",
     "iopub.status.idle": "2024-03-01T10:06:18.092292Z",
     "shell.execute_reply": "2024-03-01T10:06:18.091846Z",
     "shell.execute_reply.started": "2024-03-01T10:06:14.840027Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "partition: noniid-labeldir\n",
      "Data statistics Train: {0: {0: 2921, 1: 3, 2: 1440, 3: 2284, 4: 2849, 5: 1966}, 1: {0: 1265, 1: 1562, 2: 515, 4: 1070, 5: 496, 6: 2247, 7: 308, 8: 11, 9: 2637}, 2: {0: 91, 1: 124, 2: 203, 3: 2255, 4: 93, 5: 489, 6: 898, 7: 2460, 8: 283, 9: 2268}, 3: {0: 543, 1: 31, 2: 1028, 3: 61, 4: 987, 5: 534, 6: 4, 7: 2214, 8: 47, 9: 95}, 4: {0: 180, 1: 3280, 2: 1814, 3: 400, 4: 1, 5: 1515, 6: 1851, 7: 18, 8: 4659}}\n",
      "Data statistics Test:\n",
      " {0: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000}, 1: {0: 1000, 1: 1000, 2: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}, 2: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}, 3: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}, 4: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# partition\n",
    "net_dataidx_map, net_dataidx_map_test, traindata_cls_counts, testdata_cls_counts = partition_data(dataset, data_path, partition, client_num)\n",
    "\n",
    "# get dataloader\n",
    "train_loader_list = []\n",
    "test_loader_list = []\n",
    "for idx in range(client_num):\n",
    "    \n",
    "    dataidxs = net_dataidx_map[idx]\n",
    "    if net_dataidx_map_test is None:\n",
    "        dataidx_test = None \n",
    "    else:\n",
    "        dataidxs_test = net_dataidx_map_test[idx]\n",
    "\n",
    "    train_dl_local, test_dl_local, train_ds_local, test_ds_local = get_dataloader(dataset, \n",
    "                                                                   data_path, batch_size, test_batch, \n",
    "                                                                   dataidxs, dataidxs_test)\n",
    "    train_loader_list.append(train_dl_local)\n",
    "    test_loader_list.append(test_dl_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:18.092792Z",
     "iopub.status.busy": "2024-03-01T10:06:18.092707Z",
     "iopub.status.idle": "2024-03-01T10:06:18.806654Z",
     "shell.execute_reply": "2024-03-01T10:06:18.806187Z",
     "shell.execute_reply.started": "2024-03-01T10:06:18.092783Z"
    },
    "id": "M8EAqvNK75NR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = ResNet18()\n",
    "client_model = BYOL_Client()\n",
    "server_model = BYOL_Server()\n",
    "server_model.cuda()\n",
    "\n",
    "client_weights = [1/5 for i in range(client_num)]\n",
    "client_models = [copy.deepcopy(client_model).cuda() for idx in range(client_num)]\n",
    "# server_models = [copy.deepcopy(server_model).cuda() for idx in range(client_num)]\n",
    "\n",
    "optimizer_server = torch.optim.Adam(server_model.parameters(), lr = H[3]) \n",
    "optimizer_clients = [torch.optim.Adam(client_models[i].parameters(), lr = H[3]) for i in range(len(client_models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:18.807245Z",
     "iopub.status.busy": "2024-03-01T10:06:18.807120Z",
     "iopub.status.idle": "2024-03-01T10:06:19.461549Z",
     "shell.execute_reply": "2024-03-01T10:06:19.461135Z",
     "shell.execute_reply.started": "2024-03-01T10:06:18.807232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796\n"
     ]
    }
   ],
   "source": [
    "# if using checkpoint to train\n",
    "# epoch = 0\n",
    "checkpath = save_path + \"/checkpoint.pth.tar\" \n",
    "checkpoint = torch.load(checkpath)\n",
    "epoch = checkpoint['glepoch']\n",
    "print(epoch)\n",
    "optimizer_server.load_state_dict(checkpoint['optimizer'][0])\n",
    "for localmodel in client_models:\n",
    "    localmodel.online_encoder.load_state_dict(checkpoint['state_dict'])\n",
    "for clientidx in range(client_num):\n",
    "    optimizer_clients[clientidx].load_state_dict(checkpoint['optimizer'][clientidx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:19.462150Z",
     "iopub.status.busy": "2024-03-01T10:06:19.462048Z",
     "iopub.status.idle": "2024-03-01T10:06:19.464867Z",
     "shell.execute_reply": "2024-03-01T10:06:19.464593Z",
     "shell.execute_reply.started": "2024-03-01T10:06:19.462140Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BYOL_Client(\n",
       "  (online_encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0)\n",
       "    (fc): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:19.465230Z",
     "iopub.status.busy": "2024-03-01T10:06:19.465154Z",
     "iopub.status.idle": "2024-03-01T10:06:19.475618Z",
     "shell.execute_reply": "2024-03-01T10:06:19.475383Z",
     "shell.execute_reply.started": "2024-03-01T10:06:19.465221Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(client_models, server_model, optimizer_server, optimizer_clients, rounds, batch_size, avg_freq):\n",
    "   \n",
    "    # training loss\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    best_accuracy = 0\n",
    "    avg_times = 0\n",
    "    # measure time\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "    # writer = SummaryWriter(f'logs/SplitFSSL_BYOL32_DifAvgtimes/resnet18Maxpooling_cifar10_{batch_size}_{avg_freq}_{noniid_ratio}_{client_num}')\n",
    "    writer = SummaryWriter(f'logs/SplitFSSL_BYOL_Avg25times/resnet18Maxpooling_cifar10_{batch_size}_{avg_freq}_{partition}_{client_num}')\n",
    "    global_step = 0\n",
    "    for curr_round in range(epoch, rounds + 1):\n",
    "        metrics = defaultdict(list)\n",
    "        print(f\"Global Round:\", curr_round)\n",
    "        w, local_loss = [], []\n",
    "        \n",
    "        num_batch = 0\n",
    "        for i in train_loader_list:\n",
    "            if num_batch < len(i):\n",
    "                num_batch = len(i)\n",
    "                \n",
    "        train_iter = []\n",
    "        for i in train_loader_list:\n",
    "            train_iter.append(iter(i))\n",
    "            \n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        p_bar = tqdm(range(num_batch))\n",
    "\n",
    "        # 聚合頻率參數成指數成長\n",
    "        # alpha = expavg_times(curr_round)\n",
    "        # 聚合頻率參數線性數成長\n",
    "        alpha = linear_growth(curr_round)\n",
    "        \n",
    "        for batch in range(num_batch):\n",
    "            # print(\"0>\", time.time() - start)\n",
    "            optimizer_zero_grads(optimizer_server, optimizer_clients)\n",
    "            \n",
    "            online_proj_one_list = [None for _ in range(5)]\n",
    "            online_proj_two_list = [None for _ in range(5)]\n",
    "            target_proj_one_list = [None for _ in range(5)]\n",
    "            target_proj_two_list = [None for _ in range(5)]\n",
    "\n",
    "            # client forward\n",
    "            # select 5 client to join training\n",
    "            s_clients = []\n",
    "            s_clients = random.sample(range(client_num), 5)\n",
    "            # print(\"1>\", time.time() - start)\n",
    "            for i, client_id in enumerate(s_clients):\n",
    "                # print(\"Client: \",i)\n",
    "                # Compute a local update\n",
    "                # print(i, \"0>\", time.time() - start)\n",
    "                img1, img2 = next_data_batch(train_iter[client_id], train_loader_list[client_id])\n",
    "                \n",
    "                img1 = img1.cuda()\n",
    "                img2 = img2.cuda()\n",
    "                \n",
    "                data_time.update(time.time() - start)\n",
    "                # print(i, \"1>\", time.time() - start)\n",
    "                # pass to client model\n",
    "                # print(\"pass to client model\")\n",
    "                client_models[client_id].train()\n",
    "                # print(i, \"2>\", time.time() - start)\n",
    "                online_proj_one, online_proj_two, target_proj_one, target_proj_two = client_models[client_id](img1, img2)\n",
    "                # print(i, \"3>\", time.time() - start)\n",
    "                \n",
    "                # store representations\n",
    "                online_proj_one_list[i] = online_proj_one\n",
    "                online_proj_two_list[i] = online_proj_two\n",
    "                target_proj_one_list[i] = target_proj_one\n",
    "                target_proj_two_list[i] = target_proj_two\n",
    "                  \n",
    "\n",
    "            # stack representations\n",
    "            stack_online_proj_one = torch.cat(online_proj_one_list, dim = 0)\n",
    "            stack_online_proj_two = torch.cat(online_proj_two_list, dim = 0)\n",
    "            stack_target_proj_one = torch.cat(target_proj_one_list, dim = 0)\n",
    "            stack_target_proj_two = torch.cat(target_proj_two_list, dim = 0)\n",
    "\n",
    "            # print(\">\", time.time() - start)\n",
    "            stack_online_proj_one, stack_online_proj_two, stack_target_proj_one, stack_target_proj_two = stack_online_proj_one.cuda(), stack_online_proj_two.cuda(), stack_target_proj_one.cuda(), stack_target_proj_two.cuda()\n",
    "            \n",
    "            # server computes\n",
    "            # print(\"server computes\")\n",
    "            online_proj_one_grad, online_proj_two_grad, loss = train_server(stack_online_proj_one.detach(), stack_online_proj_two.detach(), stack_target_proj_one, stack_target_proj_two, server_model)\n",
    "            local_loss.append((loss.item()))\n",
    "            optimizer_server.step()\n",
    "            \n",
    "            # print(time.time() - start)\n",
    "            # distribute gradients to clients\n",
    "            # online_proj_one_grad, online_proj_two_grad = online_proj_one_grad.cpu(), online_proj_two_grad.cpu()\n",
    "            gradient_dict_one = {key: [] for key in range(client_num)}\n",
    "            gradient_dict_two = {key: [] for key in range(client_num)}\n",
    "            \n",
    "            for j in range(5):\n",
    "                gradient_dict_one[j] = online_proj_one_grad[j*batch_size:(j+1)*batch_size, :]\n",
    "                gradient_dict_two[j] = online_proj_two_grad[j*batch_size:(j+1)*batch_size, :]\n",
    "                \n",
    "            \n",
    "            for i, client_id in enumerate(s_clients):\n",
    "                online_proj_one_list[i].backward(gradient_dict_one[i])\n",
    "                online_proj_two_list[i].backward(gradient_dict_two[i])\n",
    "                optimizer_clients[client_id].step()\n",
    "                client_models[client_id].update_moving_average()\n",
    "            \n",
    "            # if (batch+1)%10 == 0:\n",
    "            #     print(f\"Step [{batch}/{num_batch}]:\\tLoss: {loss.item()}\")\n",
    "            \n",
    "            del img1, img2\n",
    "            writer.add_scalar(\"Loss/train_step\", loss, global_step)\n",
    "            metrics[\"Loss/train\"].append(loss.item())\n",
    "            global_step += 1\n",
    "            \n",
    "            batch_time.update(time.time() - start)\n",
    "            start = time.time()\n",
    "            #=======================================set p_bar description=======================================================\n",
    "            p_bar.set_description(\"Train Epoch: {epoch}/{epochs:4}. Iter: {batch:4}/{iter:4}. Data: {data:.3f}s. alpha: {ep_alpha}. Batch: {bt:.3f}s. Loss: {loss:.4f}.\".format(\n",
    "                    epoch=curr_round,\n",
    "                    epochs=rounds+1,\n",
    "                    batch=batch + 1,\n",
    "                    iter=num_batch,\n",
    "                    data=data_time.avg,\n",
    "                    ep_alpha = alpha,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=loss.item()))\n",
    "            p_bar.update()\n",
    "            #=======================================set p_bar description=======================================================\n",
    "            # in 32 batch size will have 250 batches, if aggregate per 10 batches will have 25 aggerations in one epoch\n",
    "            # in 64 batch size will have 125 batches, if aggregate per 5 batches will have 25 aggerations in one epoch\n",
    "            if batch == num_batch - 1 or ((batch+1) % alpha == 0):\n",
    "                # print(\"aggregate batch\", batch)\n",
    "                avg_times += 1\n",
    "                with torch.no_grad():\n",
    "                    # aggregate client models\n",
    "                    for key in client_model.state_dict().keys():\n",
    "                        # num_batches_tracked is a non trainable LongTensor and\n",
    "                        # num_batches_tracked are the same for all clients for the given datasets\n",
    "                        if \"running\" in key or \"num_batches\" in key:\n",
    "                            continue\n",
    "                        # elif 'target' in key:\n",
    "                        #     continue\n",
    "                        else:\n",
    "                            temp = torch.zeros_like(client_model.state_dict()[key]).to('cuda')\n",
    "                            for client_idx in s_clients:\n",
    "                                temp += client_weights[client_idx] * client_models[client_idx].state_dict()[key]                        \n",
    "                            client_model.state_dict()[key].data.copy_(temp)\n",
    "                            for client_idx in range(len(client_models)):\n",
    "                                client_models[client_idx].state_dict()[key].data.copy_(client_model.state_dict()[key])\n",
    "        \n",
    "        \n",
    "        p_bar.close()\n",
    "        # scheduler_server.step()\n",
    "        for k, v in metrics.items():\n",
    "            writer.add_scalar(k, np.array(v).mean(), curr_round)\n",
    "\n",
    "\n",
    "        # loss\n",
    "        loss_avg = sum(local_loss) / len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "        if curr_round % 5 == 0:\n",
    "            optimizer_dict = []\n",
    "            optimizer_dict.append(optimizer_server.state_dict())\n",
    "            for client_idx in range(client_num):\n",
    "                optimizer_dict.append(optimizer_clients[client_idx].state_dict())\n",
    "            state_dict = client_model.online_encoder.cpu().state_dict()\n",
    "            save_checkpoint({\n",
    "                'glepoch': curr_round+1,\n",
    "                'state_dict': state_dict,\n",
    "                'optimizer': optimizer_dict,\n",
    "            }, save_path)\n",
    "        if curr_round % 100 == 0:\n",
    "            torch.save(client_model.online_encoder.cpu().state_dict(), save_path + f\"_{curr_round}_epoch.pt\")\n",
    "        \n",
    "        \n",
    "        print(f\"Global round: {curr_round} | Average loss: {loss_avg}\")\n",
    "        # print('best_accuracy:', best_accuracy, '---Round:', curr_round, '---lr', lr, '----localEpocs--', E)\n",
    "\n",
    "    end = time.time()\n",
    "   \n",
    "    print(\"Training Done!\")\n",
    "    print(\"Total time taken to Train: {}\".format(end - start))\n",
    "    print(f\"Total average times : {avg_times}\")\n",
    "\n",
    "    return client_model, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:19.475951Z",
     "iopub.status.busy": "2024-03-01T10:06:19.475876Z",
     "iopub.status.idle": "2024-03-01T10:06:19.477696Z",
     "shell.execute_reply": "2024-03-01T10:06:19.477464Z",
     "shell.execute_reply.started": "2024-03-01T10:06:19.475942Z"
    },
    "id": "fNqdWcj6d-75",
    "outputId": "27e28498-a3e7-47ef-977b-0f935619d113",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/SplitFSSL_BYOL32_DifAvgtimes/resnet18Maxpooling_cifar10_32_linear_noniid-labeldir_5\n"
     ]
    }
   ],
   "source": [
    "# plot_str = partition + '_' + norm + '_' + 'comm_rounds_' + str(global_epochs) + '_numclients_' + str(client_num) + '_clientbs_' + str(batch_size) + '_clientLR_' + str(lr)\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-01T10:06:19.477979Z",
     "iopub.status.busy": "2024-03-01T10:06:19.477900Z",
     "iopub.status.idle": "2024-03-01T18:22:03.293936Z",
     "shell.execute_reply": "2024-03-01T18:22:03.293517Z",
     "shell.execute_reply.started": "2024-03-01T10:06:19.477970Z"
    },
    "id": "g3tMYpDoerta",
    "outputId": "45a7d097-04fc-4a86-e139-8dc7ab3faeb4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Round: 796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 796/1001. Iter:  428/ 428. Data: 0.114s. alpha: 40. Batch: 0.340s. Loss: 0.0224.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 796 | Average loss: 0.062038993911173575\n",
      "Global Round: 797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 797/1001. Iter:  428/ 428. Data: 0.114s. alpha: 40. Batch: 0.338s. Loss: 0.0189.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 797 | Average loss: 0.02234139549328345\n",
      "Global Round: 798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 798/1001. Iter:  428/ 428. Data: 0.111s. alpha: 40. Batch: 0.333s. Loss: 0.0197.: 100%|█| 428/428 [02:22<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 798 | Average loss: 0.020505928538878945\n",
      "Global Round: 799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 799/1001. Iter:  428/ 428. Data: 0.114s. alpha: 40. Batch: 0.338s. Loss: 0.0187.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 799 | Average loss: 0.020184296470518424\n",
      "Global Round: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 800/1001. Iter:  428/ 428. Data: 0.114s. alpha: 40. Batch: 0.337s. Loss: 0.0184.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 801 saved\n",
      "Global round: 800 | Average loss: 0.020116345251901684\n",
      "Global Round: 801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 801/1001. Iter:  428/ 428. Data: 0.118s. alpha: 40. Batch: 0.343s. Loss: 0.0205.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 801 | Average loss: 0.020447752730067922\n",
      "Global Round: 802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 802/1001. Iter:  428/ 428. Data: 0.118s. alpha: 40. Batch: 0.343s. Loss: 0.0223.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 802 | Average loss: 0.02116208932162306\n",
      "Global Round: 803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 803/1001. Iter:  428/ 428. Data: 0.117s. alpha: 41. Batch: 0.342s. Loss: 0.0208.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 803 | Average loss: 0.02192130602600279\n",
      "Global Round: 804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 804/1001. Iter:  428/ 428. Data: 0.116s. alpha: 41. Batch: 0.340s. Loss: 0.0253.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 804 | Average loss: 0.023143773123830834\n",
      "Global Round: 805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 805/1001. Iter:  428/ 428. Data: 0.114s. alpha: 41. Batch: 0.338s. Loss: 0.0255.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 806 saved\n",
      "Global round: 805 | Average loss: 0.024675961966826535\n",
      "Global Round: 806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 806/1001. Iter:  428/ 428. Data: 0.118s. alpha: 41. Batch: 0.344s. Loss: 0.0274.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 806 | Average loss: 0.0265483527278928\n",
      "Global Round: 807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 807/1001. Iter:  428/ 428. Data: 0.117s. alpha: 41. Batch: 0.342s. Loss: 0.0281.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 807 | Average loss: 0.027811854007157768\n",
      "Global Round: 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 808/1001. Iter:  428/ 428. Data: 0.115s. alpha: 41. Batch: 0.338s. Loss: 0.0311.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 808 | Average loss: 0.029181436613793965\n",
      "Global Round: 809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 809/1001. Iter:  428/ 428. Data: 0.115s. alpha: 41. Batch: 0.340s. Loss: 0.0291.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 809 | Average loss: 0.030573553880067352\n",
      "Global Round: 810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 810/1001. Iter:  428/ 428. Data: 0.115s. alpha: 41. Batch: 0.339s. Loss: 0.0335.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 811 saved\n",
      "Global round: 810 | Average loss: 0.03185395594407743\n",
      "Global Round: 811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 811/1001. Iter:  428/ 428. Data: 0.117s. alpha: 41. Batch: 0.341s. Loss: 0.0352.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 811 | Average loss: 0.03358811647065471\n",
      "Global Round: 812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 812/1001. Iter:  428/ 428. Data: 0.114s. alpha: 41. Batch: 0.339s. Loss: 0.0360.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 812 | Average loss: 0.03485657538452717\n",
      "Global Round: 813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 813/1001. Iter:  428/ 428. Data: 0.115s. alpha: 41. Batch: 0.340s. Loss: 0.0350.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 813 | Average loss: 0.036118798828292116\n",
      "Global Round: 814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 814/1001. Iter:  428/ 428. Data: 0.116s. alpha: 41. Batch: 0.341s. Loss: 0.0358.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 814 | Average loss: 0.036916520611913965\n",
      "Global Round: 815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 815/1001. Iter:  428/ 428. Data: 0.116s. alpha: 41. Batch: 0.341s. Loss: 0.0388.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 816 saved\n",
      "Global round: 815 | Average loss: 0.03793419061977173\n",
      "Global Round: 816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 816/1001. Iter:  428/ 428. Data: 0.120s. alpha: 41. Batch: 0.346s. Loss: 0.0387.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 816 | Average loss: 0.03886413059815347\n",
      "Global Round: 817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 817/1001. Iter:  428/ 428. Data: 0.118s. alpha: 41. Batch: 0.343s. Loss: 0.0374.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 817 | Average loss: 0.03979589646490656\n",
      "Global Round: 818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 818/1001. Iter:  428/ 428. Data: 0.116s. alpha: 41. Batch: 0.342s. Loss: 0.0444.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 818 | Average loss: 0.04104218820858503\n",
      "Global Round: 819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 819/1001. Iter:  428/ 428. Data: 0.115s. alpha: 41. Batch: 0.341s. Loss: 0.0454.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 819 | Average loss: 0.042105773411621555\n",
      "Global Round: 820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 820/1001. Iter:  428/ 428. Data: 0.114s. alpha: 41. Batch: 0.338s. Loss: 0.0399.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 821 saved\n",
      "Global round: 820 | Average loss: 0.043594794147691435\n",
      "Global Round: 821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 821/1001. Iter:  428/ 428. Data: 0.118s. alpha: 41. Batch: 0.342s. Loss: 0.0451.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 821 | Average loss: 0.04389661999645634\n",
      "Global Round: 822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 822/1001. Iter:  428/ 428. Data: 0.118s. alpha: 41. Batch: 0.342s. Loss: 0.0489.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 822 | Average loss: 0.04418837944933466\n",
      "Global Round: 823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 823/1001. Iter:  428/ 428. Data: 0.114s. alpha: 42. Batch: 0.339s. Loss: 0.0455.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 823 | Average loss: 0.0452609262907895\n",
      "Global Round: 824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 824/1001. Iter:  428/ 428. Data: 0.115s. alpha: 42. Batch: 0.341s. Loss: 0.0431.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 824 | Average loss: 0.045930190917069666\n",
      "Global Round: 825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 825/1001. Iter:  428/ 428. Data: 0.118s. alpha: 42. Batch: 0.343s. Loss: 0.0434.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 826 saved\n",
      "Global round: 825 | Average loss: 0.045778597922664935\n",
      "Global Round: 826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 826/1001. Iter:  428/ 428. Data: 0.117s. alpha: 42. Batch: 0.342s. Loss: 0.0419.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 826 | Average loss: 0.04604636866460058\n",
      "Global Round: 827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 827/1001. Iter:  428/ 428. Data: 0.114s. alpha: 42. Batch: 0.337s. Loss: 0.0470.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 827 | Average loss: 0.04711564200294909\n",
      "Global Round: 828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 828/1001. Iter:  428/ 428. Data: 0.115s. alpha: 42. Batch: 0.339s. Loss: 0.0448.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 828 | Average loss: 0.04860071753473761\n",
      "Global Round: 829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 829/1001. Iter:  428/ 428. Data: 0.115s. alpha: 42. Batch: 0.339s. Loss: 0.0482.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 829 | Average loss: 0.04940300033575742\n",
      "Global Round: 830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 830/1001. Iter:  428/ 428. Data: 0.111s. alpha: 42. Batch: 0.333s. Loss: 0.0542.: 100%|█| 428/428 [02:22<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 831 saved\n",
      "Global round: 830 | Average loss: 0.05158658437953095\n",
      "Global Round: 831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 831/1001. Iter:  428/ 428. Data: 0.118s. alpha: 42. Batch: 0.342s. Loss: 0.0505.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 831 | Average loss: 0.05106012894832921\n",
      "Global Round: 832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 832/1001. Iter:  428/ 428. Data: 0.115s. alpha: 42. Batch: 0.340s. Loss: 0.0489.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 832 | Average loss: 0.051246191461997055\n",
      "Global Round: 833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 833/1001. Iter:  428/ 428. Data: 0.114s. alpha: 42. Batch: 0.338s. Loss: 0.0491.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 833 | Average loss: 0.05195144239256037\n",
      "Global Round: 834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 834/1001. Iter:  428/ 428. Data: 0.114s. alpha: 42. Batch: 0.338s. Loss: 0.0527.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 834 | Average loss: 0.052856865260645605\n",
      "Global Round: 835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 835/1001. Iter:  428/ 428. Data: 0.113s. alpha: 42. Batch: 0.337s. Loss: 0.0527.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 836 saved\n",
      "Global round: 835 | Average loss: 0.05376236125060888\n",
      "Global Round: 836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 836/1001. Iter:  428/ 428. Data: 0.119s. alpha: 42. Batch: 0.344s. Loss: 0.0582.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 836 | Average loss: 0.05514138612339151\n",
      "Global Round: 837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 837/1001. Iter:  428/ 428. Data: 0.116s. alpha: 42. Batch: 0.340s. Loss: 0.0545.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 837 | Average loss: 0.05668338348166408\n",
      "Global Round: 838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 838/1001. Iter:  428/ 428. Data: 0.115s. alpha: 42. Batch: 0.339s. Loss: 0.0544.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 838 | Average loss: 0.05577131762021335\n",
      "Global Round: 839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 839/1001. Iter:  428/ 428. Data: 0.116s. alpha: 42. Batch: 0.340s. Loss: 0.0596.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 839 | Average loss: 0.05551071803599039\n",
      "Global Round: 840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 840/1001. Iter:  428/ 428. Data: 0.117s. alpha: 42. Batch: 0.342s. Loss: 0.0539.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 841 saved\n",
      "Global round: 840 | Average loss: 0.05629165898834434\n",
      "Global Round: 841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 841/1001. Iter:  428/ 428. Data: 0.115s. alpha: 42. Batch: 0.338s. Loss: 0.0543.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 841 | Average loss: 0.05472108465836984\n",
      "Global Round: 842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 842/1001. Iter:  428/ 428. Data: 0.115s. alpha: 42. Batch: 0.339s. Loss: 0.0546.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 842 | Average loss: 0.055649493272616486\n",
      "Global Round: 843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 843/1001. Iter:  428/ 428. Data: 0.115s. alpha: 42. Batch: 0.339s. Loss: 0.0579.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 843 | Average loss: 0.057353228400243775\n",
      "Global Round: 844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 844/1001. Iter:  428/ 428. Data: 0.113s. alpha: 43. Batch: 0.336s. Loss: 0.0615.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 844 | Average loss: 0.05836722056303069\n",
      "Global Round: 845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 845/1001. Iter:  428/ 428. Data: 0.116s. alpha: 43. Batch: 0.340s. Loss: 0.0596.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 846 saved\n",
      "Global round: 845 | Average loss: 0.058701480677891\n",
      "Global Round: 846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 846/1001. Iter:  428/ 428. Data: 0.116s. alpha: 43. Batch: 0.338s. Loss: 0.0565.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 846 | Average loss: 0.058932660452185946\n",
      "Global Round: 847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 847/1001. Iter:  428/ 428. Data: 0.116s. alpha: 43. Batch: 0.341s. Loss: 0.0555.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 847 | Average loss: 0.059885771196579264\n",
      "Global Round: 848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 848/1001. Iter:  428/ 428. Data: 0.117s. alpha: 43. Batch: 0.342s. Loss: 0.0608.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 848 | Average loss: 0.05990998117932092\n",
      "Global Round: 849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 849/1001. Iter:  428/ 428. Data: 0.117s. alpha: 43. Batch: 0.343s. Loss: 0.0575.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 849 | Average loss: 0.060825349258206714\n",
      "Global Round: 850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 850/1001. Iter:  428/ 428. Data: 0.115s. alpha: 43. Batch: 0.339s. Loss: 0.0572.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 851 saved\n",
      "Global round: 850 | Average loss: 0.06036598198812142\n",
      "Global Round: 851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 851/1001. Iter:  428/ 428. Data: 0.115s. alpha: 43. Batch: 0.339s. Loss: 0.0610.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 851 | Average loss: 0.06156713612133933\n",
      "Global Round: 852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 852/1001. Iter:  428/ 428. Data: 0.115s. alpha: 43. Batch: 0.340s. Loss: 0.0615.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 852 | Average loss: 0.060983499781898806\n",
      "Global Round: 853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 853/1001. Iter:  428/ 428. Data: 0.113s. alpha: 43. Batch: 0.336s. Loss: 0.0593.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 853 | Average loss: 0.059958606923573486\n",
      "Global Round: 854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 854/1001. Iter:  428/ 428. Data: 0.112s. alpha: 43. Batch: 0.335s. Loss: 0.0633.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 854 | Average loss: 0.06159237746984881\n",
      "Global Round: 855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 855/1001. Iter:  428/ 428. Data: 0.117s. alpha: 43. Batch: 0.342s. Loss: 0.0619.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 856 saved\n",
      "Global round: 855 | Average loss: 0.06196737840388701\n",
      "Global Round: 856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 856/1001. Iter:  428/ 428. Data: 0.117s. alpha: 43. Batch: 0.342s. Loss: 0.0629.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 856 | Average loss: 0.06470673669686663\n",
      "Global Round: 857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 857/1001. Iter:  428/ 428. Data: 0.114s. alpha: 43. Batch: 0.339s. Loss: 0.0611.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 857 | Average loss: 0.06349473308214795\n",
      "Global Round: 858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 858/1001. Iter:  428/ 428. Data: 0.113s. alpha: 43. Batch: 0.336s. Loss: 0.0596.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 858 | Average loss: 0.06197735386091136\n",
      "Global Round: 859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 859/1001. Iter:  428/ 428. Data: 0.114s. alpha: 43. Batch: 0.338s. Loss: 0.0606.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 859 | Average loss: 0.06339228804284167\n",
      "Global Round: 860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 860/1001. Iter:  428/ 428. Data: 0.113s. alpha: 43. Batch: 0.336s. Loss: 0.0590.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 861 saved\n",
      "Global round: 860 | Average loss: 0.06387410969168783\n",
      "Global Round: 861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 861/1001. Iter:  428/ 428. Data: 0.119s. alpha: 43. Batch: 0.344s. Loss: 0.0616.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 861 | Average loss: 0.06366331041485906\n",
      "Global Round: 862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 862/1001. Iter:  428/ 428. Data: 0.112s. alpha: 43. Batch: 0.334s. Loss: 0.0617.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 862 | Average loss: 0.06325370973306839\n",
      "Global Round: 863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 863/1001. Iter:  428/ 428. Data: 0.112s. alpha: 43. Batch: 0.334s. Loss: 0.0575.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 863 | Average loss: 0.06332829524980527\n",
      "Global Round: 864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 864/1001. Iter:  428/ 428. Data: 0.114s. alpha: 43. Batch: 0.339s. Loss: 0.0658.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 864 | Average loss: 0.06481414237799489\n",
      "Global Round: 865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 865/1001. Iter:  428/ 428. Data: 0.113s. alpha: 44. Batch: 0.337s. Loss: 0.0623.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 866 saved\n",
      "Global round: 865 | Average loss: 0.06558959256579107\n",
      "Global Round: 866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 866/1001. Iter:  428/ 428. Data: 0.113s. alpha: 44. Batch: 0.334s. Loss: 0.0683.: 100%|█| 428/428 [02:21<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 866 | Average loss: 0.06541576386194363\n",
      "Global Round: 867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 867/1001. Iter:  428/ 428. Data: 0.114s. alpha: 44. Batch: 0.337s. Loss: 0.0650.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 867 | Average loss: 0.06523035872275028\n",
      "Global Round: 868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 868/1001. Iter:  428/ 428. Data: 0.115s. alpha: 44. Batch: 0.340s. Loss: 0.0646.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 868 | Average loss: 0.06384971175586508\n",
      "Global Round: 869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 869/1001. Iter:  428/ 428. Data: 0.116s. alpha: 44. Batch: 0.341s. Loss: 0.0723.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 869 | Average loss: 0.06322380147491381\n",
      "Global Round: 870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 870/1001. Iter:  428/ 428. Data: 0.112s. alpha: 44. Batch: 0.334s. Loss: 0.0669.: 100%|█| 428/428 [02:22<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 871 saved\n",
      "Global round: 870 | Average loss: 0.06542913393752876\n",
      "Global Round: 871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 871/1001. Iter:  428/ 428. Data: 0.116s. alpha: 44. Batch: 0.339s. Loss: 0.0683.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 871 | Average loss: 0.06553655355367984\n",
      "Global Round: 872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 872/1001. Iter:  428/ 428. Data: 0.115s. alpha: 44. Batch: 0.339s. Loss: 0.0557.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 872 | Average loss: 0.06347467095773911\n",
      "Global Round: 873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 873/1001. Iter:  428/ 428. Data: 0.113s. alpha: 44. Batch: 0.337s. Loss: 0.0667.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 873 | Average loss: 0.06295286734353438\n",
      "Global Round: 874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 874/1001. Iter:  428/ 428. Data: 0.112s. alpha: 44. Batch: 0.335s. Loss: 0.0599.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 874 | Average loss: 0.06233286198716019\n",
      "Global Round: 875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 875/1001. Iter:  428/ 428. Data: 0.116s. alpha: 44. Batch: 0.341s. Loss: 0.0644.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 876 saved\n",
      "Global round: 875 | Average loss: 0.06103134504301804\n",
      "Global Round: 876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 876/1001. Iter:  428/ 428. Data: 0.117s. alpha: 44. Batch: 0.340s. Loss: 0.0707.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 876 | Average loss: 0.06855237581462503\n",
      "Global Round: 877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 877/1001. Iter:  428/ 428. Data: 0.112s. alpha: 44. Batch: 0.334s. Loss: 0.0686.: 100%|█| 428/428 [02:22<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 877 | Average loss: 0.06670974205448249\n",
      "Global Round: 878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 878/1001. Iter:  428/ 428. Data: 0.116s. alpha: 44. Batch: 0.340s. Loss: 0.0703.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 878 | Average loss: 0.06841348196057795\n",
      "Global Round: 879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 879/1001. Iter:  428/ 428. Data: 0.111s. alpha: 44. Batch: 0.334s. Loss: 0.0688.: 100%|█| 428/428 [02:22<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 879 | Average loss: 0.06738303388495033\n",
      "Global Round: 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 880/1001. Iter:  428/ 428. Data: 0.116s. alpha: 44. Batch: 0.340s. Loss: 0.0654.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 881 saved\n",
      "Global round: 880 | Average loss: 0.06772000548891097\n",
      "Global Round: 881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 881/1001. Iter:  428/ 428. Data: 0.119s. alpha: 44. Batch: 0.343s. Loss: 0.0667.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 881 | Average loss: 0.06628408894882859\n",
      "Global Round: 882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 882/1001. Iter:  428/ 428. Data: 0.113s. alpha: 44. Batch: 0.336s. Loss: 0.0697.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 882 | Average loss: 0.06678889754498116\n",
      "Global Round: 883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 883/1001. Iter:  428/ 428. Data: 0.112s. alpha: 44. Batch: 0.333s. Loss: 0.0695.: 100%|█| 428/428 [02:22<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 883 | Average loss: 0.06737353778052553\n",
      "Global Round: 884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 884/1001. Iter:  428/ 428. Data: 0.113s. alpha: 44. Batch: 0.336s. Loss: 0.0734.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 884 | Average loss: 0.06734002621792187\n",
      "Global Round: 885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 885/1001. Iter:  428/ 428. Data: 0.114s. alpha: 44. Batch: 0.338s. Loss: 0.0697.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 886 saved\n",
      "Global round: 885 | Average loss: 0.06804715671411185\n",
      "Global Round: 886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 886/1001. Iter:  428/ 428. Data: 0.116s. alpha: 45. Batch: 0.340s. Loss: 0.0684.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 886 | Average loss: 0.0687529100192206\n",
      "Global Round: 887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 887/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.339s. Loss: 0.0680.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 887 | Average loss: 0.06788054449814503\n",
      "Global Round: 888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 888/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.338s. Loss: 0.0653.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 888 | Average loss: 0.0670434159844696\n",
      "Global Round: 889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 889/1001. Iter:  428/ 428. Data: 0.116s. alpha: 45. Batch: 0.340s. Loss: 0.0699.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 889 | Average loss: 0.06663963570320439\n",
      "Global Round: 890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 890/1001. Iter:  428/ 428. Data: 0.114s. alpha: 45. Batch: 0.338s. Loss: 0.0644.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 891 saved\n",
      "Global round: 890 | Average loss: 0.06632584782543584\n",
      "Global Round: 891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 891/1001. Iter:  428/ 428. Data: 0.117s. alpha: 45. Batch: 0.341s. Loss: 0.0712.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 891 | Average loss: 0.06825827719278146\n",
      "Global Round: 892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 892/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.340s. Loss: 0.0659.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 892 | Average loss: 0.06758192883125533\n",
      "Global Round: 893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 893/1001. Iter:  428/ 428. Data: 0.114s. alpha: 45. Batch: 0.338s. Loss: 0.0687.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 893 | Average loss: 0.06645162885782317\n",
      "Global Round: 894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 894/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.340s. Loss: 0.0639.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 894 | Average loss: 0.06678528503175372\n",
      "Global Round: 895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 895/1001. Iter:  428/ 428. Data: 0.114s. alpha: 45. Batch: 0.340s. Loss: 0.0635.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 896 saved\n",
      "Global round: 895 | Average loss: 0.06516340317500528\n",
      "Global Round: 896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 896/1001. Iter:  428/ 428. Data: 0.117s. alpha: 45. Batch: 0.342s. Loss: 0.0686.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 896 | Average loss: 0.06667038699977587\n",
      "Global Round: 897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 897/1001. Iter:  428/ 428. Data: 0.116s. alpha: 45. Batch: 0.344s. Loss: 0.0765.: 100%|█| 428/428 [02:27<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 897 | Average loss: 0.06680372260754631\n",
      "Global Round: 898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 898/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.339s. Loss: 0.0727.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 898 | Average loss: 0.06761452394633372\n",
      "Global Round: 899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 899/1001. Iter:  428/ 428. Data: 0.116s. alpha: 45. Batch: 0.343s. Loss: 0.0659.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 899 | Average loss: 0.06661033675631631\n",
      "Global Round: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 900/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.340s. Loss: 0.0658.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 901 saved\n",
      "Global round: 900 | Average loss: 0.06628853145325295\n",
      "Global Round: 901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 901/1001. Iter:  428/ 428. Data: 0.120s. alpha: 45. Batch: 0.345s. Loss: 0.0733.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 901 | Average loss: 0.06696103113729542\n",
      "Global Round: 902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 902/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.341s. Loss: 0.0630.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 902 | Average loss: 0.06540696149709348\n",
      "Global Round: 903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 903/1001. Iter:  428/ 428. Data: 0.112s. alpha: 45. Batch: 0.334s. Loss: 0.0674.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 903 | Average loss: 0.06575790613402273\n",
      "Global Round: 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 904/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.340s. Loss: 0.0663.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 904 | Average loss: 0.06647020359044876\n",
      "Global Round: 905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 905/1001. Iter:  428/ 428. Data: 0.118s. alpha: 45. Batch: 0.343s. Loss: 0.0693.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 906 saved\n",
      "Global round: 905 | Average loss: 0.06783574286883122\n",
      "Global Round: 906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 906/1001. Iter:  428/ 428. Data: 0.115s. alpha: 45. Batch: 0.338s. Loss: 0.0673.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 906 | Average loss: 0.06759162132288808\n",
      "Global Round: 907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 907/1001. Iter:  428/ 428. Data: 0.112s. alpha: 46. Batch: 0.335s. Loss: 0.0663.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 907 | Average loss: 0.06605472973608803\n",
      "Global Round: 908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 908/1001. Iter:  428/ 428. Data: 0.113s. alpha: 46. Batch: 0.338s. Loss: 0.0718.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 908 | Average loss: 0.06632336766119594\n",
      "Global Round: 909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 909/1001. Iter:  428/ 428. Data: 0.113s. alpha: 46. Batch: 0.338s. Loss: 0.0635.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 909 | Average loss: 0.06567617612847379\n",
      "Global Round: 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 910/1001. Iter:  428/ 428. Data: 0.114s. alpha: 46. Batch: 0.339s. Loss: 0.0659.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 911 saved\n",
      "Global round: 910 | Average loss: 0.06331291353486687\n",
      "Global Round: 911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 911/1001. Iter:  428/ 428. Data: 0.117s. alpha: 46. Batch: 0.341s. Loss: 0.0725.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 911 | Average loss: 0.06513317374982566\n",
      "Global Round: 912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 912/1001. Iter:  428/ 428. Data: 0.116s. alpha: 46. Batch: 0.342s. Loss: 0.0437.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 912 | Average loss: 0.05754960855799858\n",
      "Global Round: 913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 913/1001. Iter:  428/ 428. Data: 0.114s. alpha: 46. Batch: 0.338s. Loss: 0.0542.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 913 | Average loss: 0.056519025962834604\n",
      "Global Round: 914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 914/1001. Iter:  428/ 428. Data: 0.115s. alpha: 46. Batch: 0.340s. Loss: 0.0548.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 914 | Average loss: 0.055566106957740315\n",
      "Global Round: 915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 915/1001. Iter:  428/ 428. Data: 0.116s. alpha: 46. Batch: 0.341s. Loss: 0.0481.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 916 saved\n",
      "Global round: 915 | Average loss: 0.05266528399051907\n",
      "Global Round: 916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 916/1001. Iter:  428/ 428. Data: 0.117s. alpha: 46. Batch: 0.342s. Loss: 0.0499.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 916 | Average loss: 0.04954237517874653\n",
      "Global Round: 917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 917/1001. Iter:  428/ 428. Data: 0.115s. alpha: 46. Batch: 0.340s. Loss: 0.0471.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 917 | Average loss: 0.048635825105707776\n",
      "Global Round: 918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 918/1001. Iter:  428/ 428. Data: 0.114s. alpha: 46. Batch: 0.338s. Loss: 0.0544.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 918 | Average loss: 0.04846834938833925\n",
      "Global Round: 919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 919/1001. Iter:  428/ 428. Data: 0.116s. alpha: 46. Batch: 0.340s. Loss: 0.0339.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 919 | Average loss: 0.04592537600547075\n",
      "Global Round: 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 920/1001. Iter:  428/ 428. Data: 0.114s. alpha: 46. Batch: 0.338s. Loss: 0.0568.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 921 saved\n",
      "Global round: 920 | Average loss: 0.04730127075095182\n",
      "Global Round: 921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 921/1001. Iter:  428/ 428. Data: 0.117s. alpha: 46. Batch: 0.342s. Loss: 0.0455.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 921 | Average loss: 0.04821066114024442\n",
      "Global Round: 922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 922/1001. Iter:  428/ 428. Data: 0.114s. alpha: 46. Batch: 0.339s. Loss: 0.0411.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 922 | Average loss: 0.04762922729600534\n",
      "Global Round: 923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 923/1001. Iter:  428/ 428. Data: 0.117s. alpha: 46. Batch: 0.343s. Loss: 0.0295.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 923 | Average loss: 0.04569981365560371\n",
      "Global Round: 924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 924/1001. Iter:  428/ 428. Data: 0.115s. alpha: 46. Batch: 0.340s. Loss: 0.0474.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 924 | Average loss: 0.04710473487084018\n",
      "Global Round: 925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 925/1001. Iter:  428/ 428. Data: 0.115s. alpha: 46. Batch: 0.341s. Loss: 0.0353.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 926 saved\n",
      "Global round: 925 | Average loss: 0.04591248883369649\n",
      "Global Round: 926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 926/1001. Iter:  428/ 428. Data: 0.116s. alpha: 46. Batch: 0.341s. Loss: 0.0487.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 926 | Average loss: 0.044038931538881824\n",
      "Global Round: 927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 927/1001. Iter:  428/ 428. Data: 0.112s. alpha: 46. Batch: 0.337s. Loss: 0.0365.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 927 | Average loss: 0.045285698683566855\n",
      "Global Round: 928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 928/1001. Iter:  428/ 428. Data: 0.115s. alpha: 47. Batch: 0.340s. Loss: 0.0505.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 928 | Average loss: 0.04944603525049915\n",
      "Global Round: 929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 929/1001. Iter:  428/ 428. Data: 0.117s. alpha: 47. Batch: 0.342s. Loss: 0.0493.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 929 | Average loss: 0.05087758299990374\n",
      "Global Round: 930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 930/1001. Iter:  428/ 428. Data: 0.114s. alpha: 47. Batch: 0.338s. Loss: 0.0480.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 931 saved\n",
      "Global round: 930 | Average loss: 0.04792980579485264\n",
      "Global Round: 931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 931/1001. Iter:  428/ 428. Data: 0.117s. alpha: 47. Batch: 0.340s. Loss: 0.0429.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 931 | Average loss: 0.04790374443422411\n",
      "Global Round: 932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 932/1001. Iter:  428/ 428. Data: 0.113s. alpha: 47. Batch: 0.339s. Loss: 0.0395.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 932 | Average loss: 0.04653025877653299\n",
      "Global Round: 933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 933/1001. Iter:  428/ 428. Data: 0.113s. alpha: 47. Batch: 0.336s. Loss: 0.0457.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 933 | Average loss: 0.04612579170579665\n",
      "Global Round: 934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 934/1001. Iter:  428/ 428. Data: 0.116s. alpha: 47. Batch: 0.341s. Loss: 0.0481.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 934 | Average loss: 0.047371272276216576\n",
      "Global Round: 935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 935/1001. Iter:  428/ 428. Data: 0.112s. alpha: 47. Batch: 0.336s. Loss: 0.0443.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 936 saved\n",
      "Global round: 935 | Average loss: 0.04534064642388687\n",
      "Global Round: 936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 936/1001. Iter:  428/ 428. Data: 0.117s. alpha: 47. Batch: 0.342s. Loss: 0.0483.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 936 | Average loss: 0.04358934165439873\n",
      "Global Round: 937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 937/1001. Iter:  428/ 428. Data: 0.113s. alpha: 47. Batch: 0.336s. Loss: 0.0430.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 937 | Average loss: 0.04438006483610267\n",
      "Global Round: 938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 938/1001. Iter:  428/ 428. Data: 0.115s. alpha: 47. Batch: 0.340s. Loss: 0.0538.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 938 | Average loss: 0.0450442971130746\n",
      "Global Round: 939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 939/1001. Iter:  428/ 428. Data: 0.115s. alpha: 47. Batch: 0.340s. Loss: 0.0425.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 939 | Average loss: 0.044007026420679884\n",
      "Global Round: 940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 940/1001. Iter:  428/ 428. Data: 0.115s. alpha: 47. Batch: 0.339s. Loss: 0.0409.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 941 saved\n",
      "Global round: 940 | Average loss: 0.04340808676712424\n",
      "Global Round: 941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 941/1001. Iter:  428/ 428. Data: 0.119s. alpha: 47. Batch: 0.345s. Loss: 0.0477.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 941 | Average loss: 0.04413364677054581\n",
      "Global Round: 942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 942/1001. Iter:  428/ 428. Data: 0.114s. alpha: 47. Batch: 0.338s. Loss: 0.0446.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 942 | Average loss: 0.044125496135659026\n",
      "Global Round: 943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 943/1001. Iter:  428/ 428. Data: 0.114s. alpha: 47. Batch: 0.339s. Loss: 0.0595.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 943 | Average loss: 0.04355089235441568\n",
      "Global Round: 944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 944/1001. Iter:  428/ 428. Data: 0.114s. alpha: 47. Batch: 0.338s. Loss: 0.0412.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 944 | Average loss: 0.042418400021531036\n",
      "Global Round: 945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 945/1001. Iter:  428/ 428. Data: 0.113s. alpha: 47. Batch: 0.339s. Loss: 0.0384.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 946 saved\n",
      "Global round: 945 | Average loss: 0.0418494428272977\n",
      "Global Round: 946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 946/1001. Iter:  428/ 428. Data: 0.117s. alpha: 47. Batch: 0.343s. Loss: 0.0506.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 946 | Average loss: 0.04300511537868286\n",
      "Global Round: 947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 947/1001. Iter:  428/ 428. Data: 0.113s. alpha: 47. Batch: 0.336s. Loss: 0.0439.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 947 | Average loss: 0.04395147285067311\n",
      "Global Round: 948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 948/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.338s. Loss: 0.0501.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 948 | Average loss: 0.04248579659838682\n",
      "Global Round: 949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 949/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.338s. Loss: 0.0444.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 949 | Average loss: 0.04222388482417598\n",
      "Global Round: 950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 950/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.338s. Loss: 0.0425.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 951 saved\n",
      "Global round: 950 | Average loss: 0.0420153669830168\n",
      "Global Round: 951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 951/1001. Iter:  428/ 428. Data: 0.117s. alpha: 48. Batch: 0.342s. Loss: 0.0313.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 951 | Average loss: 0.04295063692919701\n",
      "Global Round: 952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 952/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.338s. Loss: 0.0434.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 952 | Average loss: 0.043155997856650676\n",
      "Global Round: 953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 953/1001. Iter:  428/ 428. Data: 0.109s. alpha: 48. Batch: 0.329s. Loss: 0.0370.: 100%|█| 428/428 [02:20<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 953 | Average loss: 0.04211094425817099\n",
      "Global Round: 954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 954/1001. Iter:  428/ 428. Data: 0.112s. alpha: 48. Batch: 0.335s. Loss: 0.0379.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 954 | Average loss: 0.04236034650755959\n",
      "Global Round: 955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 955/1001. Iter:  428/ 428. Data: 0.116s. alpha: 48. Batch: 0.341s. Loss: 0.0455.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 956 saved\n",
      "Global round: 955 | Average loss: 0.04142546215503712\n",
      "Global Round: 956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 956/1001. Iter:  428/ 428. Data: 0.118s. alpha: 48. Batch: 0.344s. Loss: 0.0476.: 100%|█| 428/428 [02:26<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 956 | Average loss: 0.042087785573241034\n",
      "Global Round: 957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 957/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.337s. Loss: 0.0517.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 957 | Average loss: 0.04226018093247837\n",
      "Global Round: 958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 958/1001. Iter:  428/ 428. Data: 0.113s. alpha: 48. Batch: 0.337s. Loss: 0.0369.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 958 | Average loss: 0.04227911768411504\n",
      "Global Round: 959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 959/1001. Iter:  428/ 428. Data: 0.113s. alpha: 48. Batch: 0.338s. Loss: 0.0491.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 959 | Average loss: 0.04242045595963424\n",
      "Global Round: 960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 960/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.339s. Loss: 0.0448.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 961 saved\n",
      "Global round: 960 | Average loss: 0.04208980866699157\n",
      "Global Round: 961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 961/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.338s. Loss: 0.0342.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 961 | Average loss: 0.040746441463478535\n",
      "Global Round: 962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 962/1001. Iter:  428/ 428. Data: 0.113s. alpha: 48. Batch: 0.338s. Loss: 0.0394.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 962 | Average loss: 0.0408304422205993\n",
      "Global Round: 963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 963/1001. Iter:  428/ 428. Data: 0.113s. alpha: 48. Batch: 0.337s. Loss: 0.0377.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 963 | Average loss: 0.04024235861567415\n",
      "Global Round: 964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 964/1001. Iter:  428/ 428. Data: 0.112s. alpha: 48. Batch: 0.336s. Loss: 0.0368.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 964 | Average loss: 0.03932756345249086\n",
      "Global Round: 965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 965/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.338s. Loss: 0.0371.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 966 saved\n",
      "Global round: 965 | Average loss: 0.039168340184456\n",
      "Global Round: 966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 966/1001. Iter:  428/ 428. Data: 0.115s. alpha: 48. Batch: 0.338s. Loss: 0.0427.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 966 | Average loss: 0.03959157536345943\n",
      "Global Round: 967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 967/1001. Iter:  428/ 428. Data: 0.109s. alpha: 48. Batch: 0.332s. Loss: 0.0375.: 100%|█| 428/428 [02:21<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 967 | Average loss: 0.039218947730923645\n",
      "Global Round: 968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 968/1001. Iter:  428/ 428. Data: 0.114s. alpha: 48. Batch: 0.338s. Loss: 0.0396.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 968 | Average loss: 0.03940557952639516\n",
      "Global Round: 969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 969/1001. Iter:  428/ 428. Data: 0.116s. alpha: 49. Batch: 0.340s. Loss: 0.0290.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 969 | Average loss: 0.0401701626028413\n",
      "Global Round: 970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 970/1001. Iter:  428/ 428. Data: 0.115s. alpha: 49. Batch: 0.339s. Loss: 0.0383.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 971 saved\n",
      "Global round: 970 | Average loss: 0.03953110990245069\n",
      "Global Round: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 971/1001. Iter:  428/ 428. Data: 0.114s. alpha: 49. Batch: 0.337s. Loss: 0.0495.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 971 | Average loss: 0.03970235375966007\n",
      "Global Round: 972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 972/1001. Iter:  428/ 428. Data: 0.115s. alpha: 49. Batch: 0.340s. Loss: 0.0284.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 972 | Average loss: 0.039823989497027666\n",
      "Global Round: 973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 973/1001. Iter:  428/ 428. Data: 0.113s. alpha: 49. Batch: 0.337s. Loss: 0.0369.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 973 | Average loss: 0.039494700851702244\n",
      "Global Round: 974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 974/1001. Iter:  428/ 428. Data: 0.112s. alpha: 49. Batch: 0.335s. Loss: 0.0412.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 974 | Average loss: 0.039415493154915694\n",
      "Global Round: 975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 975/1001. Iter:  428/ 428. Data: 0.113s. alpha: 49. Batch: 0.337s. Loss: 0.0447.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 976 saved\n",
      "Global round: 975 | Average loss: 0.03866844968957322\n",
      "Global Round: 976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 976/1001. Iter:  428/ 428. Data: 0.115s. alpha: 49. Batch: 0.337s. Loss: 0.0347.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 976 | Average loss: 0.03933264829966927\n",
      "Global Round: 977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 977/1001. Iter:  428/ 428. Data: 0.113s. alpha: 49. Batch: 0.337s. Loss: 0.0460.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 977 | Average loss: 0.040000122118845724\n",
      "Global Round: 978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 978/1001. Iter:  428/ 428. Data: 0.114s. alpha: 49. Batch: 0.339s. Loss: 0.0409.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 978 | Average loss: 0.03880033519327919\n",
      "Global Round: 979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 979/1001. Iter:  428/ 428. Data: 0.115s. alpha: 49. Batch: 0.340s. Loss: 0.0370.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 979 | Average loss: 0.038825775640276824\n",
      "Global Round: 980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 980/1001. Iter:  428/ 428. Data: 0.113s. alpha: 49. Batch: 0.339s. Loss: 0.0379.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 981 saved\n",
      "Global round: 980 | Average loss: 0.03921847860111254\n",
      "Global Round: 981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 981/1001. Iter:  428/ 428. Data: 0.115s. alpha: 49. Batch: 0.339s. Loss: 0.0389.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 981 | Average loss: 0.038938142550743626\n",
      "Global Round: 982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 982/1001. Iter:  428/ 428. Data: 0.114s. alpha: 49. Batch: 0.338s. Loss: 0.0465.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 982 | Average loss: 0.0381816184217824\n",
      "Global Round: 983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 983/1001. Iter:  428/ 428. Data: 0.116s. alpha: 49. Batch: 0.340s. Loss: 0.0327.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 983 | Average loss: 0.037812498515628484\n",
      "Global Round: 984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 984/1001. Iter:  428/ 428. Data: 0.112s. alpha: 49. Batch: 0.335s. Loss: 0.0370.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 984 | Average loss: 0.037717944785743675\n",
      "Global Round: 985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 985/1001. Iter:  428/ 428. Data: 0.113s. alpha: 49. Batch: 0.336s. Loss: 0.0361.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 986 saved\n",
      "Global round: 985 | Average loss: 0.03827193572629835\n",
      "Global Round: 986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 986/1001. Iter:  428/ 428. Data: 0.115s. alpha: 49. Batch: 0.339s. Loss: 0.0413.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 986 | Average loss: 0.03842349014044783\n",
      "Global Round: 987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 987/1001. Iter:  428/ 428. Data: 0.111s. alpha: 49. Batch: 0.336s. Loss: 0.0369.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 987 | Average loss: 0.03855939287361558\n",
      "Global Round: 988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 988/1001. Iter:  428/ 428. Data: 0.114s. alpha: 49. Batch: 0.338s. Loss: 0.0375.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 988 | Average loss: 0.0387832201390623\n",
      "Global Round: 989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 989/1001. Iter:  428/ 428. Data: 0.115s. alpha: 49. Batch: 0.340s. Loss: 0.0349.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 989 | Average loss: 0.03776553038629555\n",
      "Global Round: 990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 990/1001. Iter:  428/ 428. Data: 0.115s. alpha: 50. Batch: 0.339s. Loss: 0.0463.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 991 saved\n",
      "Global round: 990 | Average loss: 0.038363681292318014\n",
      "Global Round: 991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 991/1001. Iter:  428/ 428. Data: 0.116s. alpha: 50. Batch: 0.340s. Loss: 0.0349.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 991 | Average loss: 0.0375311830533651\n",
      "Global Round: 992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 992/1001. Iter:  428/ 428. Data: 0.115s. alpha: 50. Batch: 0.340s. Loss: 0.0253.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 992 | Average loss: 0.03717406309061797\n",
      "Global Round: 993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 993/1001. Iter:  428/ 428. Data: 0.111s. alpha: 50. Batch: 0.335s. Loss: 0.0303.: 100%|█| 428/428 [02:23<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 993 | Average loss: 0.037556201506789046\n",
      "Global Round: 994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 994/1001. Iter:  428/ 428. Data: 0.113s. alpha: 50. Batch: 0.337s. Loss: 0.0396.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 994 | Average loss: 0.037093786574969784\n",
      "Global Round: 995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 995/1001. Iter:  428/ 428. Data: 0.114s. alpha: 50. Batch: 0.339s. Loss: 0.0332.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 996 saved\n",
      "Global round: 995 | Average loss: 0.036591082872283236\n",
      "Global Round: 996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 996/1001. Iter:  428/ 428. Data: 0.116s. alpha: 50. Batch: 0.340s. Loss: 0.0264.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 996 | Average loss: 0.03682185840470908\n",
      "Global Round: 997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 997/1001. Iter:  428/ 428. Data: 0.113s. alpha: 50. Batch: 0.337s. Loss: 0.0431.: 100%|█| 428/428 [02:24<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 997 | Average loss: 0.0372247489682773\n",
      "Global Round: 998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 998/1001. Iter:  428/ 428. Data: 0.115s. alpha: 50. Batch: 0.340s. Loss: 0.0360.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 998 | Average loss: 0.036094299926657546\n",
      "Global Round: 999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 999/1001. Iter:  428/ 428. Data: 0.116s. alpha: 50. Batch: 0.341s. Loss: 0.0424.: 100%|█| 428/428 [02:25<00:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 999 | Average loss: 0.03611148377688967\n",
      "Global Round: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1000/1001. Iter:  428/ 428. Data: 0.115s. alpha: 50. Batch: 0.339s. Loss: 0.0380.: 100%|█| 428/428 [02:24<00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 1001 saved\n",
      "Global round: 1000 | Average loss: 0.03666778144679059\n",
      "Training Done!\n",
      "Total time taken to Train: 1.4159431457519531\n",
      "Total average times : 2045\n"
     ]
    }
   ],
   "source": [
    "client_models, train_loss = training(client_models, server_model, optimizer_server, optimizer_clients, H[0], H[2], H[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T18:22:03.294570Z",
     "iopub.status.busy": "2024-03-01T18:22:03.294484Z",
     "iopub.status.idle": "2024-03-01T18:22:03.337121Z",
     "shell.execute_reply": "2024-03-01T18:22:03.336757Z",
     "shell.execute_reply.started": "2024-03-01T18:22:03.294561Z"
    },
    "id": "h5St42vvK2Jj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(client_model.online_encoder.cpu().state_dict(), save_path + \"_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T18:22:03.337599Z",
     "iopub.status.busy": "2024-03-01T18:22:03.337516Z",
     "iopub.status.idle": "2024-03-01T18:22:03.672896Z",
     "shell.execute_reply": "2024-03-01T18:22:03.672592Z",
     "shell.execute_reply.started": "2024-03-01T18:22:03.337590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-01T18:22:03.673314Z",
     "iopub.status.busy": "2024-03-01T18:22:03.673189Z",
     "iopub.status.idle": "2024-03-01T18:22:03.675438Z",
     "shell.execute_reply": "2024-03-01T18:22:03.675185Z",
     "shell.execute_reply.started": "2024-03-01T18:22:03.673304Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "\n",
    "# %tensorboard --logdir=logs//SplitFSSL_BYOL32_DifAvgtimes --bind_all --port=7057"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-splitfedssl]",
   "language": "python",
   "name": "conda-env-.conda-splitfedssl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
