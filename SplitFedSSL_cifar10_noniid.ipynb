{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.023540Z",
     "iopub.status.busy": "2024-02-15T05:13:28.023422Z",
     "iopub.status.idle": "2024-02-15T05:13:28.514478Z",
     "shell.execute_reply": "2024-02-15T05:13:28.514154Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.023526Z"
    },
    "id": "UBt1XYXhaqmG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haken/.conda/envs/splitfedssl/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import wraps\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, utils, datasets\n",
    "from argparse import ArgumentParser\n",
    "from torchvision import transforms as tt\n",
    "from PIL import Image\n",
    "from utils import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.515282Z",
     "iopub.status.busy": "2024-02-15T05:13:28.515173Z",
     "iopub.status.idle": "2024-02-15T05:13:28.553147Z",
     "shell.execute_reply": "2024-02-15T05:13:28.552745Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.515274Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "# from utils.training import *\n",
    "# from utils.training_batch import *\n",
    "from utils.model import *\n",
    "from utils.BYOL_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.553564Z",
     "iopub.status.busy": "2024-02-15T05:13:28.553477Z",
     "iopub.status.idle": "2024-02-15T05:13:28.555318Z",
     "shell.execute_reply": "2024-02-15T05:13:28.555074Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.553554Z"
    },
    "id": "80RsLgxtasod",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set manual seed for reproducibility\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.555657Z",
     "iopub.status.busy": "2024-02-15T05:13:28.555584Z",
     "iopub.status.idle": "2024-02-15T05:13:28.559331Z",
     "shell.execute_reply": "2024-02-15T05:13:28.559124Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.555649Z"
    },
    "id": "iIARTSyVa0xH",
    "outputId": "7103c049-17fa-4339-a8a2-d2884cac6bf3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2185d0f190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.559688Z",
     "iopub.status.busy": "2024-02-15T05:13:28.559609Z",
     "iopub.status.idle": "2024-02-15T05:13:28.561218Z",
     "shell.execute_reply": "2024-02-15T05:13:28.561010Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.559680Z"
    },
    "id": "Vv3ALBpva13d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpu training specific\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.561518Z",
     "iopub.status.busy": "2024-02-15T05:13:28.561443Z",
     "iopub.status.idle": "2024-02-15T05:13:28.563181Z",
     "shell.execute_reply": "2024-02-15T05:13:28.562961Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.561511Z"
    }
   },
   "outputs": [],
   "source": [
    "# ('mnist', 'femnist', 'fmnist', 'cifar10', 'cifar100', 'svhn')\n",
    "data_path = \"./data\"\n",
    "dataset = \"cifar10\"\n",
    "# ('noniid-labeldir', 'iid', 'default') default only for femnist\n",
    "partition = \"iid\"\n",
    "test_batch = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.564110Z",
     "iopub.status.busy": "2024-02-15T05:13:28.564026Z",
     "iopub.status.idle": "2024-02-15T05:13:28.566504Z",
     "shell.execute_reply": "2024-02-15T05:13:28.566287Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.564101Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters_List (H) = [rounds, client_fraction, number_of_clients, number_of_training_rounds_local, local_batch_size, lr_client]\n",
    "\n",
    "stop_gradient = True\n",
    "has_predictor = True\n",
    "OneLayer = \"1_layer\"\n",
    "TwoLayer = \"2_layer\"\n",
    "predictor_network=TwoLayer\n",
    "global_epochs = 1000\n",
    "# global_epochs = 3\n",
    "client_fraction = 1.0\n",
    "client_num = 5\n",
    "local_epoch = 5\n",
    "batch_size = 32\n",
    "lr = 3e-4\n",
    "partition = 'iid'\n",
    "norm = 'bn'\n",
    "alpha_partition = 0.5\n",
    "sch_flag = False\n",
    "iid = False\n",
    "# 8 batch_size avg_freq = 40(25)\n",
    "# 16 batch_size avg_freq = 20(25)\n",
    "# 32 batch_size avg_freq = 2(125)\n",
    "# 32 batch_size avg_freq = 5(50)\n",
    "# 32 batch_size avg_freq = 10(25)\n",
    "# 32 batch_size avg_freq = 25(10)\n",
    "# 32 batch_size avg_freq = 50(5)\n",
    "# 64 batch_size avg_freq = 5(25)\n",
    "# 128 batch_size avg_freq = 3(21)\n",
    "avg_freq = 10\n",
    "\n",
    "\n",
    "data_portion = 1.0\n",
    "noniid_ratio = 1.0\n",
    "# noniid_ratio = 0.55\n",
    "\n",
    "# save_path = f\"./model/SplitFSSLMaxpool_resnet18/resnet18Maxpooling_cifar10_{batch_size}_{noniid_ratio}_{client_num}\"\n",
    "save_path = f\"./model/SplitFSSL_BYOL_Avg25times/resnet18Maxpooling_cifar10_{batch_size}_{avg_freq}_{partition}_{client_num}\"\n",
    "# save_path = f\"./model/SplitFSSL_BYOL32_DifAvgtimes/resnet18Maxpooling_cifar10_{batch_size}_{avg_freq}_{noniid_ratio}_{client_num}\"\n",
    "H = [global_epochs, client_fraction, client_num, local_epoch, batch_size, lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.566881Z",
     "iopub.status.busy": "2024-02-15T05:13:28.566802Z",
     "iopub.status.idle": "2024-02-15T05:13:28.568579Z",
     "shell.execute_reply": "2024-02-15T05:13:28.568342Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.566874Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, checkpoint, filename= 'checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    os.makedirs(checkpoint, exist_ok=True)\n",
    "    torch.save(state, filepath)\n",
    "    print(f'global epoch {state[\"glepoch\"]} saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:28.568916Z",
     "iopub.status.busy": "2024-02-15T05:13:28.568837Z",
     "iopub.status.idle": "2024-02-15T05:13:31.862463Z",
     "shell.execute_reply": "2024-02-15T05:13:31.862025Z",
     "shell.execute_reply.started": "2024-02-15T05:13:28.568907Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "partition: iid\n",
      "Data statistics Train: {0: {0: 987, 1: 1003, 2: 982, 3: 1057, 4: 966, 5: 950, 6: 1009, 7: 1015, 8: 1027, 9: 1004}, 1: {0: 1002, 1: 999, 2: 982, 3: 1020, 4: 1035, 5: 992, 6: 1067, 7: 923, 8: 997, 9: 983}, 2: {0: 1009, 1: 1012, 2: 1037, 3: 974, 4: 998, 5: 1004, 6: 960, 7: 997, 8: 1003, 9: 1006}, 3: {0: 1030, 1: 938, 2: 978, 3: 993, 4: 1050, 5: 1032, 6: 969, 7: 1021, 8: 964, 9: 1025}, 4: {0: 972, 1: 1048, 2: 1021, 3: 956, 4: 951, 5: 1022, 6: 995, 7: 1044, 8: 1009, 9: 982}}\n",
      "Data statistics Test:\n",
      " {0: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}, 1: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}, 2: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}, 3: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}, 4: {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# partition\n",
    "net_dataidx_map, net_dataidx_map_test, traindata_cls_counts, testdata_cls_counts = partition_data(dataset, data_path, partition, client_num)\n",
    "\n",
    "# get dataloader\n",
    "train_loader_list = []\n",
    "test_loader_list = []\n",
    "for idx in range(client_num):\n",
    "    \n",
    "    dataidxs = net_dataidx_map[idx]\n",
    "    if net_dataidx_map_test is None:\n",
    "        dataidx_test = None \n",
    "    else:\n",
    "        dataidxs_test = net_dataidx_map_test[idx]\n",
    "\n",
    "    train_dl_local, test_dl_local, train_ds_local, test_ds_local = get_dataloader(dataset, \n",
    "                                                                   data_path, batch_size, test_batch, \n",
    "                                                                   dataidxs, dataidxs_test)\n",
    "    train_loader_list.append(train_dl_local)\n",
    "    test_loader_list.append(test_dl_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.862935Z",
     "iopub.status.busy": "2024-02-15T05:13:31.862843Z",
     "iopub.status.idle": "2024-02-15T05:13:31.869214Z",
     "shell.execute_reply": "2024-02-15T05:13:31.868946Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.862925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    # feature expansion\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"ResNet\n",
    "    Note two main differences from official pytorch version:\n",
    "    1. conv1 kernel size: pytorch version uses kernel_size=7\n",
    "    2. average pooling: pytorch version uses AdaptiveAvgPool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.feature_dim = 512 * block.expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # after conv1 do max pooling\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64 , num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128 , num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256 , num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512 , num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d((4, 4))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18(num_classes=10):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.869581Z",
     "iopub.status.busy": "2024-02-15T05:13:31.869506Z",
     "iopub.status.idle": "2024-02-15T05:13:31.881084Z",
     "shell.execute_reply": "2024-02-15T05:13:31.880815Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.869573Z"
    },
    "id": "qVsY91KFuGMo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.881447Z",
     "iopub.status.busy": "2024-02-15T05:13:31.881369Z",
     "iopub.status.idle": "2024-02-15T05:13:31.883510Z",
     "shell.execute_reply": "2024-02-15T05:13:31.883261Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.881439Z"
    },
    "id": "02agk4BtuF4a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmentation utils\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn, p):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.883877Z",
     "iopub.status.busy": "2024-02-15T05:13:31.883801Z",
     "iopub.status.idle": "2024-02-15T05:13:31.885835Z",
     "shell.execute_reply": "2024-02-15T05:13:31.885589Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.883869Z"
    },
    "id": "nRBBTYFkuSfC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.886133Z",
     "iopub.status.busy": "2024-02-15T05:13:31.886062Z",
     "iopub.status.idle": "2024-02-15T05:13:31.888402Z",
     "shell.execute_reply": "2024-02-15T05:13:31.888173Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.886126Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_moving_average(ema_updater, ma_model, current_model):\n",
    "    for current_params, ma_params in zip(\n",
    "            current_model.parameters(), ma_model.parameters()\n",
    "    ):\n",
    "        old_weight, up_weight = ma_params.data, current_params.data\n",
    "        ma_params.data = ema_updater.update_average(old_weight, up_weight)\n",
    "\n",
    "\n",
    "def byol_loss_fn(x, y):\n",
    "    x = F.normalize(x, dim=-1, p=2)\n",
    "    y = F.normalize(y, dim=-1, p=2)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.888745Z",
     "iopub.status.busy": "2024-02-15T05:13:31.888674Z",
     "iopub.status.idle": "2024-02-15T05:13:31.891188Z",
     "shell.execute_reply": "2024-02-15T05:13:31.890954Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.888738Z"
    },
    "id": "zDWCgMneuVTC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, projection_size, hidden_size=4096, num_layer=TwoLayer):\n",
    "        super().__init__()\n",
    "        self.in_features = dim\n",
    "        if num_layer == OneLayer:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(dim, projection_size),\n",
    "            )\n",
    "        elif num_layer == TwoLayer:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(dim, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(hidden_size, projection_size),\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Not defined MLP: {num_layer}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.891664Z",
     "iopub.status.busy": "2024-02-15T05:13:31.891590Z",
     "iopub.status.idle": "2024-02-15T05:13:31.924802Z",
     "shell.execute_reply": "2024-02-15T05:13:31.924399Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.891657Z"
    },
    "id": "jhkMK8o6LU4S",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#client model\n",
    "class BYOL_Client(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        net=ResNet18(),\n",
    "        image_size=32,\n",
    "        projection_size=2048,\n",
    "        projection_hidden_size=4096,\n",
    "        moving_average_decay=0.99,\n",
    "        stop_gradient=True,\n",
    "        has_predictor=True,\n",
    "        predictor_network=TwoLayer,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.online_encoder = net\n",
    "        if not hasattr(net, 'feature_dim'):\n",
    "            feature_dim = list(net.children())[-1].in_features\n",
    "        else:\n",
    "            feature_dim = net.feature_dim\n",
    "        self.online_encoder.fc = MLP(feature_dim, projection_size, projection_hidden_size)  # projector\n",
    "\n",
    "        self.target_encoder = None\n",
    "        self.target_ema_updater = EMA(moving_average_decay)\n",
    "\n",
    "        self.stop_gradient = stop_gradient\n",
    "        self.has_predictor = has_predictor\n",
    "        \n",
    "        # debug purpose\n",
    "        # self.forward(torch.randn(2, 3, image_size, image_size), torch.randn(2, 3, image_size, image_size))\n",
    "        # self.reset_moving_average()\n",
    "        \n",
    "    def _get_target_encoder(self):\n",
    "        target_encoder = copy.deepcopy(self.online_encoder)\n",
    "        return target_encoder\n",
    "\n",
    "    def reset_moving_average(self):\n",
    "        del self.target_encoder\n",
    "        self.target_encoder = None\n",
    "\n",
    "    def update_moving_average(self):\n",
    "        assert (\n",
    "                self.target_encoder is not None\n",
    "        ), \"target encoder has not been created yet\"\n",
    "        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n",
    "\n",
    "    def forward(self, image_one, image_two):\n",
    "        online_proj_one = self.online_encoder(image_one)\n",
    "        online_proj_two = self.online_encoder(image_two)\n",
    "\n",
    "        # online_pred_one = self.online_predictor(online_proj_one)\n",
    "        # online_pred_two = self.online_predictor(online_proj_two)\n",
    "\n",
    "        if self.stop_gradient:\n",
    "            with torch.no_grad():\n",
    "                if self.target_encoder is None:\n",
    "                    self.target_encoder = self._get_target_encoder()\n",
    "                target_proj_one = self.target_encoder(image_one)\n",
    "                target_proj_two = self.target_encoder(image_two)\n",
    "\n",
    "                target_proj_one = target_proj_one.detach()\n",
    "                target_proj_two = target_proj_two.detach()\n",
    "\n",
    "\n",
    "        # loss_one = loss_fn(online_pred_one, target_proj_two.detach())\n",
    "        # loss_two = loss_fn(online_pred_two, target_proj_one.detach())\n",
    "\n",
    "        # loss = loss_one + loss_two\n",
    "        return online_proj_one, online_proj_two, target_proj_one, target_proj_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.925239Z",
     "iopub.status.busy": "2024-02-15T05:13:31.925160Z",
     "iopub.status.idle": "2024-02-15T05:13:31.927798Z",
     "shell.execute_reply": "2024-02-15T05:13:31.927551Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.925230Z"
    },
    "id": "brGo4ARd7nja",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# server model\n",
    "class BYOL_Server(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        projection_size=2048,\n",
    "        projection_hidden_size=4096,\n",
    "        moving_average_decay=0.99,\n",
    "        predictor_network=TwoLayer,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.online_predictor = MLP(projection_size, projection_size, projection_hidden_size, predictor_network)\n",
    "\n",
    "    def forward(self, online_proj_one, online_proj_two, target_proj_one, target_proj_two):\n",
    "\n",
    "        online_pred_one = self.online_predictor(online_proj_one)\n",
    "        online_pred_two = self.online_predictor(online_proj_two)\n",
    "\n",
    "\n",
    "        loss_one = byol_loss_fn(online_pred_one, target_proj_two)\n",
    "        loss_two = byol_loss_fn(online_pred_two, target_proj_one)\n",
    "        loss = loss_one + loss_two\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.928121Z",
     "iopub.status.busy": "2024-02-15T05:13:31.928048Z",
     "iopub.status.idle": "2024-02-15T05:13:31.931114Z",
     "shell.execute_reply": "2024-02-15T05:13:31.930873Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.928114Z"
    },
    "id": "1nIJ4fxMAYqH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformsSimCLR:\n",
    "    \"\"\"\n",
    "    A stochastic data augmentation module that transforms any given data example randomly \n",
    "    resulting in two correlated views of the same example,\n",
    "    denoted x ̃i and x ̃j, which we consider as a positive pair.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        s = 1\n",
    "        color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "        )\n",
    "        CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "        CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
    "        self.train_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomResizedCrop(size=size),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
    "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
    "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize(size=size),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                # torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                # torchvision.transforms.Normalize(CIFAR100_TRAIN_MEAN, CIFAR100_TRAIN_STD)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.train_transform(x), self.train_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:31.931430Z",
     "iopub.status.busy": "2024-02-15T05:13:31.931357Z",
     "iopub.status.idle": "2024-02-15T05:13:32.551376Z",
     "shell.execute_reply": "2024-02-15T05:13:32.551032Z",
     "shell.execute_reply.started": "2024-02-15T05:13:31.931422Z"
    },
    "id": "M8EAqvNK75NR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = ResNet18()\n",
    "client_model = BYOL_Client(net=net, stop_gradient=stop_gradient, has_predictor=has_predictor, predictor_network=predictor_network)\n",
    "server_model = BYOL_Server()\n",
    "server_model.cuda()\n",
    "\n",
    "client_weights = [1/5 for i in range(client_num)]\n",
    "client_models = [copy.deepcopy(client_model).cuda() for idx in range(client_num)]\n",
    "# server_models = [copy.deepcopy(server_model).cuda() for idx in range(client_num)]\n",
    "\n",
    "optimizer_server = torch.optim.Adam(server_model.parameters(), lr = H[5]) \n",
    "optimizer_clients = [torch.optim.Adam(client_models[i].parameters(), lr = H[5]) for i in range(len(client_models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.551851Z",
     "iopub.status.busy": "2024-02-15T05:13:32.551746Z",
     "iopub.status.idle": "2024-02-15T05:13:32.553768Z",
     "shell.execute_reply": "2024-02-15T05:13:32.553503Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.551843Z"
    }
   },
   "outputs": [],
   "source": [
    "# if using checkpoint to train\n",
    "epoch = 0\n",
    "# checkpath = save_path + \"/checkpoint.pth.tar\" \n",
    "# checkpoint = torch.load(checkpath)\n",
    "# epoch = checkpoint['glepoch']\n",
    "# print(epoch)\n",
    "# optimizer_server.load_state_dict(checkpoint['optimizer'][0])\n",
    "# for localmodel in client_models:\n",
    "#     localmodel.online_encoder.load_state_dict(checkpoint['state_dict'])\n",
    "# for clientidx in range(client_num):\n",
    "#     optimizer_clients[clientidx].load_state_dict(checkpoint['optimizer'][clientidx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.554146Z",
     "iopub.status.busy": "2024-02-15T05:13:32.554066Z",
     "iopub.status.idle": "2024-02-15T05:13:32.564300Z",
     "shell.execute_reply": "2024-02-15T05:13:32.564051Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.554137Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BYOL_Client(\n",
       "  (online_encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=(4, 4), stride=(4, 4), padding=0)\n",
       "    (fc): MLP(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "        (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.565598Z",
     "iopub.status.busy": "2024-02-15T05:13:32.565514Z",
     "iopub.status.idle": "2024-02-15T05:13:32.567504Z",
     "shell.execute_reply": "2024-02-15T05:13:32.567257Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.565588Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class create_iterator():\n",
    "    def __init__(self, iterator) -> None:\n",
    "        self.iterator = iterator\n",
    "\n",
    "    def __next__(self):\n",
    "        return next(self.iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.567805Z",
     "iopub.status.busy": "2024-02-15T05:13:32.567731Z",
     "iopub.status.idle": "2024-02-15T05:13:32.569715Z",
     "shell.execute_reply": "2024-02-15T05:13:32.569468Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.567797Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_iterator_list = []\n",
    "\n",
    "for client_id in range(client_num):\n",
    "    client_iterator_list.append(create_iterator(iter((train_loader_list[client_id]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.570116Z",
     "iopub.status.busy": "2024-02-15T05:13:32.570038Z",
     "iopub.status.idle": "2024-02-15T05:13:32.572623Z",
     "shell.execute_reply": "2024-02-15T05:13:32.572375Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.570107Z"
    },
    "id": "3YMN8FNA8DQH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_server(online_proj_one, online_proj_two, target_proj_one, target_proj_two, server_model):\n",
    "    \n",
    "    # print(\"shape\", online_proj_one.shape)\n",
    "    # print(\"online_proj_one\", online_proj_one)\n",
    "    \n",
    "    \n",
    "    online_proj_one.requires_grad = True\n",
    "    online_proj_two.requires_grad = True\n",
    "    \n",
    "    online_proj_one.retain_grad()\n",
    "    online_proj_two.retain_grad()\n",
    "\n",
    "    server_model.train()\n",
    "    \n",
    "    # forward prop\n",
    "    loss = server_model(online_proj_one, online_proj_two, target_proj_one, target_proj_two)\n",
    "    \n",
    "    if online_proj_one.grad is not None:\n",
    "        online_proj_one.grad.zero_()\n",
    "        \n",
    "    if online_proj_two.grad is not None:\n",
    "        online_proj_two.grad.zero_()\n",
    "            \n",
    "    # backward prop\n",
    "    loss.backward()\n",
    "    online_proj_one_grad, online_proj_two_grad = online_proj_one.grad.detach().clone(), online_proj_two.grad.detach().clone()\n",
    "    # print(\"online_proj_one_grad\", online_proj_one_grad.shape)\n",
    "    # print(\"online_proj_two_grad\", online_proj_two_grad.shape)\n",
    "    \n",
    "    return online_proj_one_grad, online_proj_two_grad, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.572958Z",
     "iopub.status.busy": "2024-02-15T05:13:32.572886Z",
     "iopub.status.idle": "2024-02-15T05:13:32.574750Z",
     "shell.execute_reply": "2024-02-15T05:13:32.574519Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.572950Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimizer_zero_grads(optimizer_server, optimizer_clients):  # This needs to be called\n",
    "    optimizer_server.zero_grad()\n",
    "    for i in range(client_num):\n",
    "        optimizer_clients[i].zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.575096Z",
     "iopub.status.busy": "2024-02-15T05:13:32.575025Z",
     "iopub.status.idle": "2024-02-15T05:13:32.577447Z",
     "shell.execute_reply": "2024-02-15T05:13:32.577203Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.575089Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read one batch of image pair\n",
    "def next_data_batch(client_id):\n",
    "    try:\n",
    "        img1, img2 = next(client_iterator_list[client_id])\n",
    "        if img1.size(0) != batch_size:\n",
    "            try:\n",
    "                next(client_iterator_list[client_id])\n",
    "            except StopIteration:\n",
    "                pass\n",
    "            client_iterator_list[client_id] = create_iterator(iter((train_loader_list[client_id])))\n",
    "            img1, img2 = next(client_iterator_list[client_id])\n",
    "    except StopIteration:\n",
    "        client_iterator_list[client_id] = create_iterator(iter((train_loader_list[client_id])))\n",
    "        img1, img2 = next(client_iterator_list[client_id])\n",
    "    return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.577789Z",
     "iopub.status.busy": "2024-02-15T05:13:32.577715Z",
     "iopub.status.idle": "2024-02-15T05:13:32.587513Z",
     "shell.execute_reply": "2024-02-15T05:13:32.587270Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.577781Z"
    },
    "id": "aSuc_o8KbhVQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(client_models, server_model, optimizer_server, optimizer_clients, rounds, batch_size, lr, C, K, local_epochs, plt_title, plt_color, cifar_data_test=None,\n",
    "             test_batch_size=None, criterion=None, num_classes=None, classes_test=None, sch_flag=None):\n",
    "   \n",
    "    # training loss\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    best_accuracy = 0\n",
    "    avg_times = 0\n",
    "    # measure time\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "    num_batch = len(train_loader_list[0])\n",
    "    \n",
    "    # writer = SummaryWriter(f'logs/SplitFSSL_BYOL32_DifAvgtimes/resnet18Maxpooling_cifar10_{batch_size}_{avg_freq}_{noniid_ratio}_{client_num}')\n",
    "    writer = SummaryWriter(f'logs/SplitFSSL_BYOL_Avg25times/resnet18Maxpooling_cifar10_{batch_size}_{avg_freq}_{noniid_ratio}_{client_num}')\n",
    "    global_step = 0\n",
    "    for curr_round in range(epoch, rounds + 1):\n",
    "        metrics = defaultdict(list)\n",
    "        print(f\"Global Round:\", curr_round)\n",
    "        w, local_loss = [], []\n",
    "        \n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        p_bar = tqdm(range(num_batch))\n",
    "        \n",
    "        for batch in range(num_batch):\n",
    "            # print(\"0>\", time.time() - start)\n",
    "            optimizer_zero_grads(optimizer_server, optimizer_clients)\n",
    "            \n",
    "            online_proj_one_list = [None for _ in range(5)]\n",
    "            online_proj_two_list = [None for _ in range(5)]\n",
    "            target_proj_one_list = [None for _ in range(5)]\n",
    "            target_proj_two_list = [None for _ in range(5)]\n",
    "\n",
    "            # client forward\n",
    "            # select 5 client to join training\n",
    "            s_clients = []\n",
    "            s_clients = random.sample(range(client_num), 5)\n",
    "            # print(\"1>\", time.time() - start)\n",
    "            for i, client_id in enumerate(s_clients):\n",
    "                # print(\"Client: \",i)\n",
    "                # Compute a local update\n",
    "                # print(i, \"0>\", time.time() - start)\n",
    "                img1, img2 = next_data_batch(client_id)\n",
    "                \n",
    "                img1 = img1.cuda()\n",
    "                img2 = img2.cuda()\n",
    "                \n",
    "                data_time.update(time.time() - start)\n",
    "                # print(i, \"1>\", time.time() - start)\n",
    "                # pass to client model\n",
    "                # print(\"pass to client model\")\n",
    "                client_models[client_id].train()\n",
    "                # print(i, \"2>\", time.time() - start)\n",
    "                online_proj_one, online_proj_two, target_proj_one, target_proj_two = client_models[client_id](img1, img2)\n",
    "                # print(i, \"3>\", time.time() - start)\n",
    "                \n",
    "                # store representations\n",
    "                online_proj_one_list[i] = online_proj_one\n",
    "                online_proj_two_list[i] = online_proj_two\n",
    "                target_proj_one_list[i] = target_proj_one\n",
    "                target_proj_two_list[i] = target_proj_two\n",
    "                  \n",
    "\n",
    "            # stack representations\n",
    "            stack_online_proj_one = torch.cat(online_proj_one_list, dim = 0)\n",
    "            stack_online_proj_two = torch.cat(online_proj_two_list, dim = 0)\n",
    "            stack_target_proj_one = torch.cat(target_proj_one_list, dim = 0)\n",
    "            stack_target_proj_two = torch.cat(target_proj_two_list, dim = 0)\n",
    "\n",
    "            # print(\">\", time.time() - start)\n",
    "            stack_online_proj_one, stack_online_proj_two, stack_target_proj_one, stack_target_proj_two = stack_online_proj_one.cuda(), stack_online_proj_two.cuda(), stack_target_proj_one.cuda(), stack_target_proj_two.cuda()\n",
    "            \n",
    "            # server computes\n",
    "            # print(\"server computes\")\n",
    "            online_proj_one_grad, online_proj_two_grad, loss = train_server(stack_online_proj_one.detach(), stack_online_proj_two.detach(), stack_target_proj_one, stack_target_proj_two, server_model)\n",
    "            local_loss.append((loss.item()))\n",
    "            optimizer_server.step()\n",
    "            \n",
    "            # print(time.time() - start)\n",
    "            # distribute gradients to clients\n",
    "            # online_proj_one_grad, online_proj_two_grad = online_proj_one_grad.cpu(), online_proj_two_grad.cpu()\n",
    "            gradient_dict_one = {key: [] for key in range(client_num)}\n",
    "            gradient_dict_two = {key: [] for key in range(client_num)}\n",
    "            \n",
    "            for j in range(5):\n",
    "                gradient_dict_one[j] = online_proj_one_grad[j*batch_size:(j+1)*batch_size, :]\n",
    "                gradient_dict_two[j] = online_proj_two_grad[j*batch_size:(j+1)*batch_size, :]\n",
    "                \n",
    "            \n",
    "            for i, client_id in enumerate(s_clients):\n",
    "                online_proj_one_list[i].backward(gradient_dict_one[i])\n",
    "                online_proj_two_list[i].backward(gradient_dict_two[i])\n",
    "                optimizer_clients[client_id].step()\n",
    "                client_models[client_id].update_moving_average()\n",
    "            \n",
    "            # if (batch+1)%10 == 0:\n",
    "            #     print(f\"Step [{batch}/{num_batch}]:\\tLoss: {loss.item()}\")\n",
    "            \n",
    "            del img1, img2\n",
    "            writer.add_scalar(\"Loss/train_step\", loss, global_step)\n",
    "            metrics[\"Loss/train\"].append(loss.item())\n",
    "            global_step += 1\n",
    "            \n",
    "            batch_time.update(time.time() - start)\n",
    "            start = time.time()\n",
    "            #=======================================set p_bar description=======================================================\n",
    "            p_bar.set_description(\"Train Epoch: {epoch}/{epochs:4}. Iter: {batch:4}/{iter:4}. Data: {data:.3f}s. Batch: {bt:.3f}s. Loss: {loss:.4f}.\".format(\n",
    "                    epoch=curr_round,\n",
    "                    epochs=rounds+1,\n",
    "                    batch=batch + 1,\n",
    "                    iter=num_batch,\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    loss=loss.item()))\n",
    "            p_bar.update()\n",
    "            #=======================================set p_bar description=======================================================\n",
    "            # in 32 batch size will have 250 batches, if aggregate per 10 batches will have 25 aggerations in one epoch\n",
    "            # in 64 batch size will have 125 batches, if aggregate per 5 batches will have 25 aggerations in one epoch\n",
    "            if batch == num_batch - 1 or ((batch+1) % avg_freq == 0):\n",
    "                print(\"aggregate batch\", batch)\n",
    "                avg_times += 1\n",
    "                with torch.no_grad():\n",
    "                    # aggregate client models\n",
    "                    for key in client_model.state_dict().keys():\n",
    "                        # num_batches_tracked is a non trainable LongTensor and\n",
    "                        # num_batches_tracked are the same for all clients for the given datasets\n",
    "                        if \"running\" in key or \"num_batches\" in key:\n",
    "                            continue\n",
    "                        # elif 'target' in key:\n",
    "                        #     continue\n",
    "                        else:\n",
    "                            temp = torch.zeros_like(client_model.state_dict()[key]).to('cuda')\n",
    "                            for client_idx in s_clients:\n",
    "                                temp += client_weights[client_idx] * client_models[client_idx].state_dict()[key]                        \n",
    "                            client_model.state_dict()[key].data.copy_(temp)\n",
    "                            for client_idx in range(len(client_models)):\n",
    "                                client_models[client_idx].state_dict()[key].data.copy_(client_model.state_dict()[key])\n",
    "        \n",
    "        \n",
    "        p_bar.close()\n",
    "        # scheduler_server.step()\n",
    "        for k, v in metrics.items():\n",
    "            writer.add_scalar(k, np.array(v).mean(), curr_round)\n",
    "\n",
    "\n",
    "        # loss\n",
    "        loss_avg = sum(local_loss) / len(local_loss)\n",
    "        train_loss.append(loss_avg)\n",
    "        if curr_round % 5 == 0:\n",
    "            optimizer_dict = []\n",
    "            optimizer_dict.append(optimizer_server.state_dict())\n",
    "            for client_idx in range(client_num):\n",
    "                optimizer_dict.append(optimizer_clients[client_idx].state_dict())\n",
    "            state_dict = client_model.online_encoder.cpu().state_dict()\n",
    "            save_checkpoint({\n",
    "                'glepoch': curr_round+1,\n",
    "                'state_dict': state_dict,\n",
    "                'optimizer': optimizer_dict,\n",
    "            }, save_path)\n",
    "        if curr_round % 100 == 0:\n",
    "            torch.save(client_model.online_encoder.cpu().state_dict(), save_path + f\"_{curr_round}_epoch.pt\")\n",
    "        \n",
    "        \n",
    "        print(f\"Global round: {curr_round} | Average loss: {loss_avg}\")\n",
    "        # print('best_accuracy:', best_accuracy, '---Round:', curr_round, '---lr', lr, '----localEpocs--', E)\n",
    "\n",
    "    end = time.time()\n",
    "   \n",
    "    print(\"Training Done!\")\n",
    "    print(\"Total time taken to Train: {}\".format(end - start))\n",
    "    print(f\"Total average times : {avg_times}\")\n",
    "\n",
    "    return client_model, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.587832Z",
     "iopub.status.busy": "2024-02-15T05:13:32.587755Z",
     "iopub.status.idle": "2024-02-15T05:13:32.590199Z",
     "shell.execute_reply": "2024-02-15T05:13:32.589947Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.587824Z"
    },
    "id": "fNqdWcj6d-75",
    "outputId": "27e28498-a3e7-47ef-977b-0f935619d113",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iid_bn_comm_rounds_1000_clientfr_1.0_numclients_5_clientepochs_5_clientbs_32_clientLR_0.0003\n"
     ]
    }
   ],
   "source": [
    "plot_str = partition + '_' + norm + '_' + 'comm_rounds_' + str(global_epochs) + '_clientfr_' + str(\n",
    "        client_fraction) + '_numclients_' + str(client_num) + '_clientepochs_' + str(\n",
    "        local_epoch) + '_clientbs_' + str(batch_size) + '_clientLR_' + str(lr)\n",
    "print(plot_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-15T05:13:32.590523Z",
     "iopub.status.busy": "2024-02-15T05:13:32.590450Z",
     "iopub.status.idle": "2024-02-15T13:03:38.068235Z",
     "shell.execute_reply": "2024-02-15T13:03:38.067757Z",
     "shell.execute_reply.started": "2024-02-15T05:13:32.590515Z"
    },
    "id": "g3tMYpDoerta",
    "outputId": "45a7d097-04fc-4a86-e139-8dc7ab3faeb4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Round: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0533.: 100%|█| 313/313 [01:55<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 1 saved\n",
      "Global round: 0 | Average loss: 0.4955434874414255\n",
      "Global Round: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.0218.: 100%|█| 313/313 [01:54<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 1 | Average loss: 0.030354390051751473\n",
      "Global Round: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0206.: 100%|█| 313/313 [01:54<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 2 | Average loss: 0.02068751166089655\n",
      "Global Round: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.0192.: 100%|█| 313/313 [01:54<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 3 | Average loss: 0.02040001550040687\n",
      "Global Round: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.0210.: 100%|█| 313/313 [01:54<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 4 | Average loss: 0.02113972971447931\n",
      "Global Round: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.363s. Loss: 0.0226.: 100%|█| 313/313 [01:53<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 6 saved\n",
      "Global round: 5 | Average loss: 0.022188148363091693\n",
      "Global Round: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.0246.: 100%|█| 313/313 [01:55<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 6 | Average loss: 0.024013914733220593\n",
      "Global Round: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0275.: 100%|█| 313/313 [01:55<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 7 | Average loss: 0.0258891683357497\n",
      "Global Round: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0320.: 100%|█| 313/313 [01:55<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 8 | Average loss: 0.02772150679042164\n",
      "Global Round: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0312.: 100%|█| 313/313 [01:54<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 9 | Average loss: 0.02979683962921365\n",
      "Global Round: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0332.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 11 saved\n",
      "Global round: 10 | Average loss: 0.03180097802854574\n",
      "Global Round: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.369s. Loss: 0.0381.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 11 | Average loss: 0.0371008581115891\n",
      "Global Round: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12/1001. Iter:  313/ 313. Data: 0.143s. Batch: 0.364s. Loss: 0.0437.: 100%|█| 313/313 [01:53<00:00,  2.75it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 12 | Average loss: 0.041350888201413444\n",
      "Global Round: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13/1001. Iter:  313/ 313. Data: 0.140s. Batch: 0.361s. Loss: 0.0529.: 100%|█| 313/313 [01:53<00:00,  2.77it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 13 | Average loss: 0.048228031018385874\n",
      "Global Round: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.0724.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 14 | Average loss: 0.060982056176319674\n",
      "Global Round: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.0748.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 16 saved\n",
      "Global round: 15 | Average loss: 0.07264801507559829\n",
      "Global Round: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.369s. Loss: 0.0450.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 16 | Average loss: 0.06335882046304572\n",
      "Global Round: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0365.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 17 | Average loss: 0.042775724815151184\n",
      "Global Round: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.0406.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 18 | Average loss: 0.04019675153893785\n",
      "Global Round: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0333.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 19 | Average loss: 0.040213515452397895\n",
      "Global Round: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.0299.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 21 saved\n",
      "Global round: 20 | Average loss: 0.03711519934260807\n",
      "Global Round: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.0256.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 21 | Average loss: 0.030320856065605396\n",
      "Global Round: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0247.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 22 | Average loss: 0.02794617185363183\n",
      "Global Round: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0306.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 23 | Average loss: 0.032948506049835645\n",
      "Global Round: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0494.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 24 | Average loss: 0.052476764332276944\n",
      "Global Round: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0540.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 26 saved\n",
      "Global round: 25 | Average loss: 0.058863625097008175\n",
      "Global Round: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.370s. Loss: 0.0557.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 26 | Average loss: 0.05274144882639757\n",
      "Global Round: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.0531.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 27 | Average loss: 0.056249092883481004\n",
      "Global Round: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0488.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 28 | Average loss: 0.048628322042215365\n",
      "Global Round: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0608.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 29 | Average loss: 0.053716746239235606\n",
      "Global Round: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0668.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 31 saved\n",
      "Global round: 30 | Average loss: 0.06461565626172212\n",
      "Global Round: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31/1001. Iter:  313/ 313. Data: 0.149s. Batch: 0.369s. Loss: 0.0681.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 31 | Average loss: 0.06989932134033391\n",
      "Global Round: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.0877.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 32 | Average loss: 0.08145216057380548\n",
      "Global Round: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.0985.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 33 | Average loss: 0.09075157256267322\n",
      "Global Round: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0931.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 34 | Average loss: 0.09180952770451006\n",
      "Global Round: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0962.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 36 saved\n",
      "Global round: 35 | Average loss: 0.08890249989569758\n",
      "Global Round: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1014.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 36 | Average loss: 0.0950369490697361\n",
      "Global Round: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.1036.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 37 | Average loss: 0.10529869118818459\n",
      "Global Round: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0913.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 38 | Average loss: 0.10509801489381364\n",
      "Global Round: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0972.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 39 | Average loss: 0.10649693397858653\n",
      "Global Round: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.0842.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 41 saved\n",
      "Global round: 40 | Average loss: 0.10394819135578295\n",
      "Global Round: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.0808.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 41 | Average loss: 0.10011187505226928\n",
      "Global Round: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42/1001. Iter:  313/ 313. Data: 0.141s. Batch: 0.361s. Loss: 0.0873.: 100%|█| 313/313 [01:52<00:00,  2.77it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 42 | Average loss: 0.09850095074397687\n",
      "Global Round: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.1041.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 43 | Average loss: 0.09894818303208001\n",
      "Global Round: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0915.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 44 | Average loss: 0.09959874713954073\n",
      "Global Round: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1068.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 46 saved\n",
      "Global round: 45 | Average loss: 0.10240142302105602\n",
      "Global Round: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 46/1001. Iter:  313/ 313. Data: 0.149s. Batch: 0.369s. Loss: 0.1119.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 46 | Average loss: 0.10946399830400753\n",
      "Global Round: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.1377.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 47 | Average loss: 0.12161170024746143\n",
      "Global Round: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1395.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 48 | Average loss: 0.1319999461785292\n",
      "Global Round: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 49/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1276.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 49 | Average loss: 0.1328471545784618\n",
      "Global Round: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 50/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.369s. Loss: 0.1366.: 100%|█| 313/313 [01:55<00:00,  2.71it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 51 saved\n",
      "Global round: 50 | Average loss: 0.13211414379814562\n",
      "Global Round: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 51/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1123.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 51 | Average loss: 0.1294277618392207\n",
      "Global Round: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 52/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.0964.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 52 | Average loss: 0.12492209908585199\n",
      "Global Round: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.363s. Loss: 0.0955.: 100%|█| 313/313 [01:53<00:00,  2.75it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 53 | Average loss: 0.1190369943507944\n",
      "Global Round: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 54/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1114.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 54 | Average loss: 0.11567059102149817\n",
      "Global Round: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 55/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.369s. Loss: 0.0910.: 100%|█| 313/313 [01:55<00:00,  2.71it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 56 saved\n",
      "Global round: 55 | Average loss: 0.11062311204953697\n",
      "Global Round: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56/1001. Iter:  313/ 313. Data: 0.151s. Batch: 0.371s. Loss: 0.0601.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 56 | Average loss: 0.10085447971670392\n",
      "Global Round: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 57/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.0740.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 57 | Average loss: 0.0876329104407146\n",
      "Global Round: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 58/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0850.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 58 | Average loss: 0.07919709886700962\n",
      "Global Round: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 59/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.0883.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 59 | Average loss: 0.0804178919821692\n",
      "Global Round: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.0866.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 61 saved\n",
      "Global round: 60 | Average loss: 0.07860702698746809\n",
      "Global Round: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 61/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0716.: 100%|█| 313/313 [01:53<00:00,  2.75it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 61 | Average loss: 0.07759445428419799\n",
      "Global Round: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 62/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.365s. Loss: 0.0718.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 62 | Average loss: 0.07788342424332144\n",
      "Global Round: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 63/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0637.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 63 | Average loss: 0.07539525426948032\n",
      "Global Round: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 64/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0579.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 64 | Average loss: 0.06942357652532026\n",
      "Global Round: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 65/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0682.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 66 saved\n",
      "Global round: 65 | Average loss: 0.06104446979709707\n",
      "Global Round: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 66/1001. Iter:  313/ 313. Data: 0.149s. Batch: 0.370s. Loss: 0.0502.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 66 | Average loss: 0.055289459030944316\n",
      "Global Round: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 67/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0510.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 67 | Average loss: 0.054796022562363655\n",
      "Global Round: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 68/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.0554.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 68 | Average loss: 0.05621924745246244\n",
      "Global Round: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 69/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0503.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 69 | Average loss: 0.05567222511092314\n",
      "Global Round: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 70/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0566.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 71 saved\n",
      "Global round: 70 | Average loss: 0.055891902885212306\n",
      "Global Round: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 71/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.0495.: 100%|█| 313/313 [01:55<00:00,  2.71it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 71 | Average loss: 0.056180649672072536\n",
      "Global Round: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 72/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.0421.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 72 | Average loss: 0.05732399971483234\n",
      "Global Round: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0687.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 73 | Average loss: 0.058848859272159326\n",
      "Global Round: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 74/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.0561.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 74 | Average loss: 0.061070779546762044\n",
      "Global Round: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 75/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0656.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 76 saved\n",
      "Global round: 75 | Average loss: 0.06419579958477721\n",
      "Global Round: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 76/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.0710.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 76 | Average loss: 0.0668249249148864\n",
      "Global Round: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 77/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0729.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 77 | Average loss: 0.07072902899294996\n",
      "Global Round: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 78/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0734.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 78 | Average loss: 0.0776711470974139\n",
      "Global Round: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 79/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0808.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 79 | Average loss: 0.0820811312205304\n",
      "Global Round: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 80/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.0850.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 81 saved\n",
      "Global round: 80 | Average loss: 0.08686635188591747\n",
      "Global Round: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 81/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0797.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 81 | Average loss: 0.09130640001818775\n",
      "Global Round: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 82/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.0957.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 82 | Average loss: 0.09116897326165115\n",
      "Global Round: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 83/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.364s. Loss: 0.1324.: 100%|█| 313/313 [01:53<00:00,  2.75it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 83 | Average loss: 0.09494050549337277\n",
      "Global Round: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 84/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1064.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 84 | Average loss: 0.09841030609969514\n",
      "Global Round: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 85/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.0870.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 86 saved\n",
      "Global round: 85 | Average loss: 0.10044533485612168\n",
      "Global Round: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 86/1001. Iter:  313/ 313. Data: 0.149s. Batch: 0.370s. Loss: 0.1088.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 86 | Average loss: 0.10172320971378503\n",
      "Global Round: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 87/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0919.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 87 | Average loss: 0.1044745417163014\n",
      "Global Round: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 88/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1318.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 88 | Average loss: 0.1056202746951542\n",
      "Global Round: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 89/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0918.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 89 | Average loss: 0.10863206140435161\n",
      "Global Round: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 90/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.0918.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 91 saved\n",
      "Global round: 90 | Average loss: 0.11110914758028695\n",
      "Global Round: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 91/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1155.: 100%|█| 313/313 [01:54<00:00,  2.74it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 91 | Average loss: 0.1118335048563945\n",
      "Global Round: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 92/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1323.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 92 | Average loss: 0.11275476838548343\n",
      "Global Round: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 93/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0853.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 93 | Average loss: 0.11575361976798731\n",
      "Global Round: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 94/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1079.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 94 | Average loss: 0.11537897658233826\n",
      "Global Round: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 95/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1330.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 96 saved\n",
      "Global round: 95 | Average loss: 0.11957604723711746\n",
      "Global Round: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 96/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1441.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 96 | Average loss: 0.12362343299027068\n",
      "Global Round: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 97/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1373.: 100%|█| 313/313 [01:54<00:00,  2.73it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 97 | Average loss: 0.12390720451506562\n",
      "Global Round: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 98/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1436.: 100%|█| 313/313 [01:55<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 98 | Average loss: 0.1286648199343072\n",
      "Global Round: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 99/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1040.: 100%|█| 313/313 [01:54<00:00,  2.72it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 99 | Average loss: 0.12982953156526097\n",
      "Global Round: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1116.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 101 saved\n",
      "Global round: 100 | Average loss: 0.13031324729942284\n",
      "Global Round: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 101/1001. Iter:  313/ 313. Data: 0.149s. Batch: 0.369s. Loss: 0.1146.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 101 | Average loss: 0.13386736222254203\n",
      "Global Round: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 102/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1614.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 102 | Average loss: 0.13213895620724644\n",
      "Global Round: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 103/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1559.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 103 | Average loss: 0.13479068082647203\n",
      "Global Round: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 104/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1582.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 104 | Average loss: 0.13560814998401238\n",
      "Global Round: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 105/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1390.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 106 saved\n",
      "Global round: 105 | Average loss: 0.1376175798309116\n",
      "Global Round: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 106/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.370s. Loss: 0.1392.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 106 | Average loss: 0.13633622498081896\n",
      "Global Round: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 107/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1549.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 107 | Average loss: 0.1391324886260703\n",
      "Global Round: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 108/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1573.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 108 | Average loss: 0.14166162174921065\n",
      "Global Round: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1510.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 109 | Average loss: 0.13943702075332878\n",
      "Global Round: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 110/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1307.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 111 saved\n",
      "Global round: 110 | Average loss: 0.1450707249986097\n",
      "Global Round: 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 111/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1109.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 111 | Average loss: 0.1454539433978617\n",
      "Global Round: 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 112/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1855.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 112 | Average loss: 0.14485665129872557\n",
      "Global Round: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 113/1001. Iter:  313/ 313. Data: 0.142s. Batch: 0.362s. Loss: 0.2094.: 100%|█| 313/313 [01:53<00:00,  2.76it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 113 | Average loss: 0.1430902193767575\n",
      "Global Round: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 114/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1143.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 114 | Average loss: 0.1461367686859335\n",
      "Global Round: 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 115/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.1316.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 116 saved\n",
      "Global round: 115 | Average loss: 0.14339757803529976\n",
      "Global Round: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 116/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1408.: 100%|█| 313/313 [01:53<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 116 | Average loss: 0.146780922985115\n",
      "Global Round: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 117/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1211.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 117 | Average loss: 0.1439843864296191\n",
      "Global Round: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 118/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1226.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 118 | Average loss: 0.14610459348454644\n",
      "Global Round: 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 119/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1393.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 119 | Average loss: 0.1472057714915504\n",
      "Global Round: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 120/1001. Iter:  313/ 313. Data: 0.143s. Batch: 0.363s. Loss: 0.1467.: 100%|█| 313/313 [01:53<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 121 saved\n",
      "Global round: 120 | Average loss: 0.14679158667025094\n",
      "Global Round: 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 121/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1871.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 121 | Average loss: 0.1459521619370951\n",
      "Global Round: 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 122/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1686.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 122 | Average loss: 0.14862660892283955\n",
      "Global Round: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 123/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1388.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 123 | Average loss: 0.14819821386862866\n",
      "Global Round: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 124/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.1793.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 124 | Average loss: 0.1450671628593637\n",
      "Global Round: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 125/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1316.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 126 saved\n",
      "Global round: 125 | Average loss: 0.14677090400133652\n",
      "Global Round: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 126/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1296.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 126 | Average loss: 0.14586893628580502\n",
      "Global Round: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 127/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1672.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 127 | Average loss: 0.1449612300997725\n",
      "Global Round: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 128/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1981.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 128 | Average loss: 0.14821751841817038\n",
      "Global Round: 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 129/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1280.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 129 | Average loss: 0.1460356321007299\n",
      "Global Round: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 130/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1589.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 131 saved\n",
      "Global round: 130 | Average loss: 0.14533943004501512\n",
      "Global Round: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 131/1001. Iter:  313/ 313. Data: 0.151s. Batch: 0.371s. Loss: 0.1543.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 131 | Average loss: 0.14613098113205486\n",
      "Global Round: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 132/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1309.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 132 | Average loss: 0.14476585326293787\n",
      "Global Round: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 133/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1459.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 133 | Average loss: 0.14843407818398918\n",
      "Global Round: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 134/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1484.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 134 | Average loss: 0.1472091527935415\n",
      "Global Round: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 135/1001. Iter:  313/ 313. Data: 0.143s. Batch: 0.363s. Loss: 0.1844.: 100%|█| 313/313 [01:53<00:00,  2.76it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 136 saved\n",
      "Global round: 135 | Average loss: 0.14511992599065313\n",
      "Global Round: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 136/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.369s. Loss: 0.1570.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 136 | Average loss: 0.14698540959685755\n",
      "Global Round: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 137/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.1207.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 137 | Average loss: 0.14764523277648342\n",
      "Global Round: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 138/1001. Iter:  313/ 313. Data: 0.143s. Batch: 0.363s. Loss: 0.1633.: 100%|█| 313/313 [01:53<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 138 | Average loss: 0.146488520641106\n",
      "Global Round: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 139/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1354.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 139 | Average loss: 0.1448368269462174\n",
      "Global Round: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 140/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1369.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 141 saved\n",
      "Global round: 140 | Average loss: 0.14654252413934032\n",
      "Global Round: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 141/1001. Iter:  313/ 313. Data: 0.151s. Batch: 0.371s. Loss: 0.1668.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 141 | Average loss: 0.14640364393639488\n",
      "Global Round: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 142/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1449.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 142 | Average loss: 0.14519063154824627\n",
      "Global Round: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 143/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1333.: 100%|█| 313/313 [01:55<00:00,  2.71it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 143 | Average loss: 0.14602175926248107\n",
      "Global Round: 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 144/1001. Iter:  313/ 313. Data: 0.141s. Batch: 0.358s. Loss: 0.1376.: 100%|█| 313/313 [01:52<00:00,  2.79it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 144 | Average loss: 0.14764932185982743\n",
      "Global Round: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 145/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1284.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 146 saved\n",
      "Global round: 145 | Average loss: 0.14639687866639026\n",
      "Global Round: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 146/1001. Iter:  313/ 313. Data: 0.149s. Batch: 0.368s. Loss: 0.1748.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 146 | Average loss: 0.14443591379890808\n",
      "Global Round: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 147/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.1454.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 147 | Average loss: 0.14526340651055114\n",
      "Global Round: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 148/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1605.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 148 | Average loss: 0.14706560593253126\n",
      "Global Round: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 149/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1486.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 149 | Average loss: 0.14569939025484335\n",
      "Global Round: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 150/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1735.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 151 saved\n",
      "Global round: 150 | Average loss: 0.14753698307675675\n",
      "Global Round: 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 151/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1430.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 151 | Average loss: 0.14621449169069053\n",
      "Global Round: 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 152/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1354.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 152 | Average loss: 0.14782395192418998\n",
      "Global Round: 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 153/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1429.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 153 | Average loss: 0.14591246681472364\n",
      "Global Round: 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 154/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.365s. Loss: 0.1408.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 154 | Average loss: 0.14637578402559598\n",
      "Global Round: 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 155/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1487.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 156 saved\n",
      "Global round: 155 | Average loss: 0.1458265387688201\n",
      "Global Round: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 156/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.370s. Loss: 0.1394.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 156 | Average loss: 0.14391405918537237\n",
      "Global Round: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 157/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.365s. Loss: 0.1511.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 157 | Average loss: 0.14484273456632138\n",
      "Global Round: 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 158/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1471.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 158 | Average loss: 0.14451690280018523\n",
      "Global Round: 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 159/1001. Iter:  313/ 313. Data: 0.142s. Batch: 0.363s. Loss: 0.1367.: 100%|█| 313/313 [01:53<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 159 | Average loss: 0.14358722701811563\n",
      "Global Round: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 160/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.369s. Loss: 0.1121.: 100%|█| 313/313 [01:55<00:00,  2.71it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 161 saved\n",
      "Global round: 160 | Average loss: 0.1438170889505563\n",
      "Global Round: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 161/1001. Iter:  313/ 313. Data: 0.151s. Batch: 0.371s. Loss: 0.1473.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 161 | Average loss: 0.14452227185995054\n",
      "Global Round: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 162/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1397.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 162 | Average loss: 0.14637216537619552\n",
      "Global Round: 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 163/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.369s. Loss: 0.1561.: 100%|█| 313/313 [01:55<00:00,  2.71it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 163 | Average loss: 0.14564128115344732\n",
      "Global Round: 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 164/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1588.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 164 | Average loss: 0.14367276784806207\n",
      "Global Round: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 165/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1296.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 166 saved\n",
      "Global round: 165 | Average loss: 0.1440596900428065\n",
      "Global Round: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 166/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1442.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 166 | Average loss: 0.1438609165743517\n",
      "Global Round: 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 167/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1621.: 100%|█| 313/313 [01:55<00:00,  2.71it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 167 | Average loss: 0.14577690626200016\n",
      "Global Round: 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 168/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1423.: 100%|█| 313/313 [01:55<00:00,  2.71it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 168 | Average loss: 0.1459478373630359\n",
      "Global Round: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 169/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.1828.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 169 | Average loss: 0.14590952750116873\n",
      "Global Round: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 170/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.364s. Loss: 0.1398.: 100%|█| 313/313 [01:53<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 171 saved\n",
      "Global round: 170 | Average loss: 0.14448218726026366\n",
      "Global Round: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 171/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.364s. Loss: 0.1439.: 100%|█| 313/313 [01:52<00:00,  2.77it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 171 | Average loss: 0.14592088075777213\n",
      "Global Round: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 172/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.364s. Loss: 0.1382.: 100%|█| 313/313 [01:53<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 172 | Average loss: 0.1473901109478344\n",
      "Global Round: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 173/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.1430.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 173 | Average loss: 0.1462501203909088\n",
      "Global Round: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 174/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.1405.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 174 | Average loss: 0.14496604312723055\n",
      "Global Round: 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 175/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.1648.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 176 saved\n",
      "Global round: 175 | Average loss: 0.14613479249679243\n",
      "Global Round: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 176/1001. Iter:  313/ 313. Data: 0.149s. Batch: 0.370s. Loss: 0.1631.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 176 | Average loss: 0.14637474075388224\n",
      "Global Round: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 177/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1237.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 177 | Average loss: 0.14721219686749645\n",
      "Global Round: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 178/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1384.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 178 | Average loss: 0.14633123533794293\n",
      "Global Round: 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 179/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1048.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 179 | Average loss: 0.1444119464475126\n",
      "Global Round: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 180/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1269.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 181 saved\n",
      "Global round: 180 | Average loss: 0.14464467697250197\n",
      "Global Round: 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 181/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1518.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 181 | Average loss: 0.1436201801029638\n",
      "Global Round: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 182/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.1415.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 182 | Average loss: 0.1426376876549218\n",
      "Global Round: 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 183/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1437.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 183 | Average loss: 0.14252939656043587\n",
      "Global Round: 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 184/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.369s. Loss: 0.1479.: 100%|█| 313/313 [01:55<00:00,  2.71it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 184 | Average loss: 0.1365563375548052\n",
      "Global Round: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 185/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1247.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 186 saved\n",
      "Global round: 185 | Average loss: 0.13711748048425101\n",
      "Global Round: 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 186/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.370s. Loss: 0.1242.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 186 | Average loss: 0.13467476714533358\n",
      "Global Round: 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 187/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.1247.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 187 | Average loss: 0.13533117710211026\n",
      "Global Round: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 188/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1154.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 188 | Average loss: 0.1338854574452574\n",
      "Global Round: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 189/1001. Iter:  313/ 313. Data: 0.142s. Batch: 0.360s. Loss: 0.1590.: 100%|█| 313/313 [01:52<00:00,  2.78it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 189 | Average loss: 0.13515577184411284\n",
      "Global Round: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 190/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1532.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 191 saved\n",
      "Global round: 190 | Average loss: 0.1352988506515567\n",
      "Global Round: 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 191/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.370s. Loss: 0.1303.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 191 | Average loss: 0.13446270217434667\n",
      "Global Round: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 192/1001. Iter:  313/ 313. Data: 0.143s. Batch: 0.361s. Loss: 0.1289.: 100%|█| 313/313 [01:53<00:00,  2.77it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 192 | Average loss: 0.13654597441609295\n",
      "Global Round: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 193/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.1075.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 193 | Average loss: 0.13493647181187957\n",
      "Global Round: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 194/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.1220.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 194 | Average loss: 0.134960181225603\n",
      "Global Round: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 195/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1244.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 196 saved\n",
      "Global round: 195 | Average loss: 0.13408566892337495\n",
      "Global Round: 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 196/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1330.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 196 | Average loss: 0.13397828051552604\n",
      "Global Round: 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 197/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1359.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 197 | Average loss: 0.13629318016786546\n",
      "Global Round: 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 198/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.1414.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 198 | Average loss: 0.1371325848106378\n",
      "Global Round: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 199/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.365s. Loss: 0.1347.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 199 | Average loss: 0.13560214472083618\n",
      "Global Round: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 200/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1213.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 201 saved\n",
      "Global round: 200 | Average loss: 0.1371625479513083\n",
      "Global Round: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 201/1001. Iter:  313/ 313. Data: 0.149s. Batch: 0.369s. Loss: 0.1174.: 100%|█| 313/313 [01:54<00:00,  2.74it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 201 | Average loss: 0.13696037849393516\n",
      "Global Round: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 202/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.0941.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 202 | Average loss: 0.13704318196152726\n",
      "Global Round: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 203/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1404.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 203 | Average loss: 0.1371554778025935\n",
      "Global Round: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 204/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1129.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 204 | Average loss: 0.13588168012638824\n",
      "Global Round: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 205/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1341.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 206 saved\n",
      "Global round: 205 | Average loss: 0.13870454160645365\n",
      "Global Round: 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 206/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.371s. Loss: 0.1651.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 206 | Average loss: 0.13723496595225015\n",
      "Global Round: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 207/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1511.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 207 | Average loss: 0.140440371922982\n",
      "Global Round: 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 208/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1400.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 208 | Average loss: 0.1395604042009043\n",
      "Global Round: 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 209/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.367s. Loss: 0.1748.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 209 | Average loss: 0.14166628309903434\n",
      "Global Round: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 210/1001. Iter:  313/ 313. Data: 0.139s. Batch: 0.360s. Loss: 0.1291.: 100%|█| 313/313 [01:52<00:00,  2.78it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 211 saved\n",
      "Global round: 210 | Average loss: 0.13976060320584538\n",
      "Global Round: 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 211/1001. Iter:  313/ 313. Data: 0.142s. Batch: 0.363s. Loss: 0.1305.: 100%|█| 313/313 [01:52<00:00,  2.78it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 211 | Average loss: 0.14154623846371714\n",
      "Global Round: 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 212/1001. Iter:  313/ 313. Data: 0.144s. Batch: 0.364s. Loss: 0.1270.: 100%|█| 313/313 [01:54<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 212 | Average loss: 0.14187937434584189\n",
      "Global Round: 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 213/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1213.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 213 | Average loss: 0.14075300992487338\n",
      "Global Round: 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 214/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1478.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 214 | Average loss: 0.1439375103757785\n",
      "Global Round: 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 215/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1516.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 216 saved\n",
      "Global round: 215 | Average loss: 0.1404930204867174\n",
      "Global Round: 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 216/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.370s. Loss: 0.1242.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 216 | Average loss: 0.1425914754168675\n",
      "Global Round: 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 217/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1279.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 217 | Average loss: 0.1411907997089453\n",
      "Global Round: 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 218/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1315.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 218 | Average loss: 0.1403715743567235\n",
      "Global Round: 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 219/1001. Iter:  313/ 313. Data: 0.145s. Batch: 0.363s. Loss: 0.1135.: 100%|█| 313/313 [01:53<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 219 | Average loss: 0.14043804408071903\n",
      "Global Round: 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 220/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1505.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 221 saved\n",
      "Global round: 220 | Average loss: 0.14036320549801898\n",
      "Global Round: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 221/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.366s. Loss: 0.1297.: 100%|█| 313/313 [01:53<00:00,  2.76it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 221 | Average loss: 0.13632562687507452\n",
      "Global Round: 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 222/1001. Iter:  313/ 313. Data: 0.142s. Batch: 0.359s. Loss: 0.1164.: 100%|█| 313/313 [01:52<00:00,  2.78it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 222 | Average loss: 0.13488881585125725\n",
      "Global Round: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 223/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1430.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 223 | Average loss: 0.13362513423061217\n",
      "Global Round: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 224/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1359.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 224 | Average loss: 0.13298352860128537\n",
      "Global Round: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 225/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1200.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 226 saved\n",
      "Global round: 225 | Average loss: 0.13390570210096553\n",
      "Global Round: 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 226/1001. Iter:  313/ 313. Data: 0.143s. Batch: 0.363s. Loss: 0.1287.: 100%|█| 313/313 [01:52<00:00,  2.78it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 226 | Average loss: 0.1335067911841237\n",
      "Global Round: 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 227/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1251.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 227 | Average loss: 0.13385269514764078\n",
      "Global Round: 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 228/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1252.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 228 | Average loss: 0.13414703259548058\n",
      "Global Round: 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 229/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1354.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 229 | Average loss: 0.13571715454895275\n",
      "Global Round: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 230/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1421.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 231 saved\n",
      "Global round: 230 | Average loss: 0.13640823355688456\n",
      "Global Round: 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 231/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.370s. Loss: 0.1165.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 231 | Average loss: 0.13647571027564545\n",
      "Global Round: 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 232/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1214.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 232 | Average loss: 0.13820319613233542\n",
      "Global Round: 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 233/1001. Iter:  313/ 313. Data: 0.140s. Batch: 0.359s. Loss: 0.1246.: 100%|█| 313/313 [01:52<00:00,  2.79it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 233 | Average loss: 0.13657185809014324\n",
      "Global Round: 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 234/1001. Iter:  313/ 313. Data: 0.146s. Batch: 0.366s. Loss: 0.1426.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 234 | Average loss: 0.1373657630369686\n",
      "Global Round: 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 235/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.368s. Loss: 0.1328.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 236 saved\n",
      "Global round: 235 | Average loss: 0.13740767783726365\n",
      "Global Round: 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 236/1001. Iter:  313/ 313. Data: 0.151s. Batch: 0.371s. Loss: 0.1405.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 236 | Average loss: 0.1367306513622546\n",
      "Global Round: 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 237/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1386.: 100%|█| 313/313 [01:55<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 237 | Average loss: 0.13581218165806688\n",
      "Global Round: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 238/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.368s. Loss: 0.1219.: 100%|█| 313/313 [01:55<00:00,  2.71it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 238 | Average loss: 0.1391177409515975\n",
      "Global Round: 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 239/1001. Iter:  313/ 313. Data: 0.143s. Batch: 0.364s. Loss: 0.1631.: 100%|█| 313/313 [01:53<00:00,  2.75it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 239 | Average loss: 0.1382516888193429\n",
      "Global Round: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 240/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1398.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch 241 saved\n",
      "Global round: 240 | Average loss: 0.1378928375796388\n",
      "Global Round: 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 241/1001. Iter:  313/ 313. Data: 0.150s. Batch: 0.370s. Loss: 0.1563.: 100%|█| 313/313 [01:54<00:00,  2.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 241 | Average loss: 0.13951686379342035\n",
      "Global Round: 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 242/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1176.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 242 | Average loss: 0.1402803946274538\n",
      "Global Round: 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 243/1001. Iter:  313/ 313. Data: 0.147s. Batch: 0.367s. Loss: 0.1181.: 100%|█| 313/313 [01:54<00:00,  2.73it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 243 | Average loss: 0.13862319885732266\n",
      "Global Round: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 244/1001. Iter:  313/ 313. Data: 0.148s. Batch: 0.374s. Loss: 0.1524.: 100%|█| 313/313 [01:56<00:00,  2.68it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global round: 244 | Average loss: 0.1397564835346545\n",
      "Global Round: 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 245/1001. Iter:  138/ 313. Data: 0.144s. Batch: 0.365s. Loss: 0.1674.:  44%|▍| 138/313 [00:49<00:59,  2.97it/"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_801779/754429636.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_model, train_loss = training(client_models, server_model, optimizer_server, optimizer_clients, H[0], H[4], H[5], H[1], H[2], H[3], plot_str,\n\u001b[0;32m----> 2\u001b[0;31m                              \"green\")\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_801779/910032605.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(client_models, server_model, optimizer_server, optimizer_clients, rounds, batch_size, lr, C, K, local_epochs, plt_title, plt_color, cifar_data_test, test_batch_size, criterion, num_classes, classes_test, sch_flag)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0monline_proj_one_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_dict_one\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0monline_proj_two_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_dict_two\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0moptimizer_clients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mclient_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_moving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/splitfedssl/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/splitfedssl/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model, train_loss = training(client_models, server_model, optimizer_server, optimizer_clients, H[0], H[4], H[5], H[1], H[2], H[3], plot_str,\n",
    "                             \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-15T13:03:38.068567Z",
     "iopub.status.idle": "2024-02-15T13:03:38.068668Z",
     "shell.execute_reply": "2024-02-15T13:03:38.068623Z",
     "shell.execute_reply.started": "2024-02-15T13:03:38.068617Z"
    },
    "id": "h5St42vvK2Jj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(client_model.online_encoder.cpu().state_dict(), save_path + \"_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-15T13:03:38.069100Z",
     "iopub.status.idle": "2024-02-15T13:03:38.069194Z",
     "shell.execute_reply": "2024-02-15T13:03:38.069150Z",
     "shell.execute_reply.started": "2024-02-15T13:03:38.069145Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-splitfedssl]",
   "language": "python",
   "name": "conda-env-.conda-splitfedssl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
